[["index.html", "Principios de bioinform√°tica y ciencias de biodatos Presentaci√≥n", " Principios de bioinform√°tica y ciencias de biodatos Alejandro Acevedo-Aracena, PhD1; Manuel Mu√±oz-Gonz√°lez2 2021-04-30 Presentaci√≥n Los avances en la obtenci√≥n de datos biol√≥gicos asociados a genes, prote√≠nas y metabolitos han dado lugar a un r√°pido aumento del volumen y complejidad de datos publicados en distintos repositorios de libre acceso (por ejemplo Gene Expression Omnibus de NCBI). Actualmente se requiere de bioinform√°ticos que apliquen herramientas bioinform√°ticas y ciencia de datos para generar resultados biol√≥gicamente interpretables desde datos complejos y diversos. Este curso est√° orientado a alumnos sin ning√∫n conocimiento previo sobre programaci√≥n y computacional ni bioinform√°tica. Se espera que al final del curso los alumnos dominen herramientas b√°sicas de bioinform√°tica y principios generales de ciencia de datos para aplicarlos en sus respectivas √°reas de investigaci√≥n. FONDECYT Postdoctoral Fellow, Universidad de Chile, deepen.data@gmail.com‚Ü©Ô∏é Pregrado, Universidad de Chile‚Ü©Ô∏é "],["setup-del-ambiente.html", "Setup del ambiente Paquetes de CRAN Paquetes de Bioconductor Instalaci√≥n de R(Studio) en Windows", " Setup del ambiente Paquetes de CRAN CRAN (Comprehensive R Archive Network) es el repositorio principal de R, con m√°s de 16,000 paquetes disponibles en multiples ambitos de analisis de datos, ciencias (astronomia, biolog√≠a, matematica, sociolog√≠a, etc.) y econom√≠a. De aqui instalamos: options(install.packages.check.source = &quot;yes&quot;) # Chequea la fuente de los paquetes install.packages(&quot;devtools&quot;) # Utilidades de manejo de archivos, descargas, etc. install.packages(&quot;tidyverse&quot;) # Set de paquetes que hacen muchas cosas # Analisis no lineal, manipulaci√≥n de texto, etc... # Paquetes que deberian estar incluidos en Tidyverse install.packages(&quot;broom&quot;) # Convierte objetos de R a Tibbles, como &quot;readr&quot; install.packages(&quot;dbplyr&quot;) # Manipulaci√≥n de bases de datps (eg. SQL) install.packages(&quot;dplyr&quot;) # Manipulaci√≥n de datos mediante gramatica propia install.packages(&quot;fs&quot;) # Operaciones agnosticas de sistemas de archivos install.packages(&quot;haven&quot;) # Trabaja con archivos SPSS, Stata y SAS install.packages(&quot;httr&quot;) # Herramientas del protocolo HTTP, como GET, etc... install.packages(&quot;magrittr&quot;) # Operadores ca√±eria (pipes) %&gt;% install.packages(&quot;modelr&quot;) # Funciones de modelado compatibles con pipes install.packages(&quot;openssl&quot;) # Trabaja con certificados y encriptaci√≥n SSL install.packages(&quot;readr&quot;) # Traducci√≥n (pharsing) de archivos a una tibble install.packages(&quot;readxl&quot;) # Permite leer archivos de Excel install.packages(&quot;stringr&quot;) # Operadores consistentes para strings install.packages(&quot;tibble&quot;) # Dataframes del Siglo 21 (moderniza sintaxis) install.packages(&quot;gapminder&quot;) # data de Gapminder install.packages(&quot;gifski&quot;) # encoding de GIFs install.packages(&quot;av&quot;) # herramientas de audio y video install.packages(&quot;webshot&quot;) # screenshots de paginas web # Paquetes de graficos install.packages(&quot;ggplot2&quot;) # Graficos complejos install.packages(&quot;GGally&quot;) # extensi√≥n de ggplot2 install.packages(&quot;ggsci&quot;) # paletas de colores para publicaci√≥n install.packages(&quot;ggpubr&quot;) # ggplot simplificado para publicaciones install.packages(&quot;gganimate&quot;) # graficos animados install.packages(&quot;ggmuller&quot;) # diagrama de evolucionarios Muller install.packages(&quot;autoplotly&quot;) # visualizaciones interactivas install.packages(&quot;gridExtra&quot;) # extensi√≥n de grid, para la creaci√≥n de figuras # Paqutes para completaci√≥n de datos install.packages(&quot;missRanger&quot;) # Permite completar data incompleta (gaps) install.packages(&quot;outForest&quot;) # Detecci√≥n y reemplazo de outliers y gaps install.packages(&quot;OutlierDetection&quot;) # Detecci√≥n avanzada de outliers Una vez instalados los paquetes, R no es necesario correr estos comandos de nuevo, solo se convocan via library(PAQUETE). El repositorio funciona como una red sincronizada, y existen dos instancias en Chile: https://cran.dcc.uchile.cl/ (Departamento de Ciencias de la Computaci√≥n) y https://cran.dme.ufro.cl/ (Departamento de Matematicas y Estadistica). Por motivos de velocidad y para reducir carga sobre la red, es recomendable cambiar la configuraci√≥n de RStudio en ‚ÄúGlobal Options / Packages / Primary CRAN Repository‚Äù y seleccionar uno de estos (asumiendo que est√©n en Chile). Paquetes de Bioconductor Existen otros repositorios especializados que contienen paquetes dedicados a areas especificas de investigaci√≥n. Bioconductor tiene una colecci√≥n dedicada al analisis de datos genomicos y pipelines asociadas a estos, con m√°s de 1,900 paquetes, y software adicional no-basado en R. Estos se actualizan semi-anualmente siguiendo los releases de R. La instalaci√≥n de Bioconductor y paquetes asociados se maneja con el paquete BiocManager, disponible en CRAN. # Instalando Bioconductor if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) # Instala BiocManager de CRAN BiocManager::install() # Instala los paquetes base de Bioconductor # Requiere input del usuario en la consola (a) # Instalando paquetes de Bioconductor BiocManager::install(&quot;Biostrings&quot;) # Manipulaci√≥n de strings en biolog√≠a BiocManager::install(&quot;biomaRt&quot;) # Acceso a bases de datos biomedicas BiocManager::install(&quot;GEOquery&quot;) # Bases de datos de expresi√≥n genica # Paquetes complejos compilados desde codigo fuente # Lasciate ogni speranza, voi ch&#39;entrate BiocManager::install(&quot;RforProteomics&quot;, # Tidiverse para prote√≥mica ask = F, # sin promps de &quot;Instalar (y/n)&quot; dependencies = TRUE, # con Dependencias type = &quot;source&quot;, # Compila de fuente checkBuilt = TRUE) # Valida install BiocManager::install(&quot;MSnbase&quot;, # Funciones para espectrometria de masas ask = F, # sin promps de &quot;Instalar (y/n)&quot; dependencies = TRUE, # con Dependencias type = &quot;source&quot;, # Compila de fuente checkBuilt = TRUE) # Valida install Instalaci√≥n de R(Studio) en Windows Usando un gestor de paquetes Un gestor de paquetes es como apt-get de Debian, o install.packages() de R. Windows no trae uno incluido, pero existen soluciones como Chocolatey. Este se instala y maneja desde la consola de comandos PowerShell. Es la opci√≥n mas r√°pida, y funciona a largo plazo para cosas que no son R3 . Abrir Powershell como administrador (para que pueda instalar programas) Ejecutar el comando Set-ExecutionPolicy Bypass -Scope Process -Force; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1')). Esto instala Chocolatey. Ejecutar el comando choco install r rtools R.Studio --yes. Esto instala R, R-Tools y RStudio. üéâ (Instalaci√≥n lista!) En resumen (que se puede copiar y pegar en PowerShell): # Instalando Chocolatey Set-ExecutionPolicy Bypass -Scope Process -Force; iex ((New-Object System.Net.WebClient).DownloadString(&#39;https://chocolatey.org/install.ps1&#39;)) # Instalando R y RStudio choco install r rtools R.Studio --yes Instalaci√≥n manual RStudio es un Integrated Development Enviroment (IDE) para R, similar a una mascara para dar una interfaz amigable. No contiene R en si. Por ello, es necesario descargar R de CRAN, instalar el ejecutable, y luego descargar e instalar RStudio. Instalando R-tools manualmente Ciertos paquetes estan escritos en C/C++ por motivos de rendimiento, por lo que Windows requiere un compilador C para instalarlos. En R, este se suple por R-tools, distribuido en forma de un instalador ejecutable (desafortunadamente no en Chocolatey). R-tools (64bit &amp; 32bit) o para sistemas antiguos de 32bit Luego, en R ejecutar writeLines(&#39;PATH=&quot;${RTOOLS40_HOME}\\\\usr\\\\bin;${PATH}&quot;&#39;, con = &quot;~/.Renviron&quot;) Sys.which(&quot;make&quot;) # la salida deberia ser &quot;C:\\\\rtools40\\\\usr\\\\bin\\\\make.exe&quot; Paquetes generales con Chocolatey El comando choco install googlechrome steam choco install chimera permite instalar Google Chrome, Steam, y UCSF Chimera, en una unica linea. Se le puede a√±adir la confirmaci√≥n si a todo con la opci√≥n --yes‚Ü©Ô∏é "],["clase-1-conceptos-generales-ejemplos-de-casos-y-nociones-de-lenguajes-de-programaci√≥n.html", "1 CLASE 1 - Conceptos generales, ejemplos de casos y nociones de lenguajes de programaci√≥n 1.1 Interacci√≥n¬†con¬†terminales 1.2 Lenguajes¬†de¬†programaci√≥n e IDEs 1.3 Introducci√≥n a R y cuadernos 1.4 Importaci√≥n y analisis de datos", " 1 CLASE 1 - Conceptos generales, ejemplos de casos y nociones de lenguajes de programaci√≥n 1.1 Interacci√≥n¬†con¬†terminales La terminal es una herramienta que nos permite comunicarnos directamente con la computadora para ejecutar acciones complejas en unos pocos comandos. En si, es similar a como trabajamos con lenguajes interpretados como R, en el sentido de que enviamos comandos y recibimos respuestas (casi) inmediatas. Dependiendo de en que sistema nos encontramos, tenemos distintas SHELLs que interpretan los comandos, siguiendo una sintaxis u otra, con distintos niveles de ayuda al usuario. Por conveniencia, usaremos principalmente BASH, que es la SHELL mas comun encontrada en entornos Linux, que a su vez son los mas comunes en tareas de programacion para datascience y bioinformatica. Es posible instalar un entorno Linux en Windows usando Windows Subsystem for Linux. La mayor parte de estos comandos existen tanto en Linux como en Windows Powershell (aunque en este ultimo realmente son alias). La principal diferencia es como las shells manejan directorios, con / en POSIX y \\ en Windows; y como manejan comandos multilinea, \\ y ` respectivamente. La parte m√°s compleja y menos interoperable es cuando usamos comandos con -parametros. 1.1.1 Navegaci√≥n del sistema ls es LiSt, mapeado a Get-ChilItem en Powershell. ls -a lista todos los objetos en el directorio, incluyendo ocultos ls -lh genera una lista en formato lista, con permisos, due√±os, grupos, tama√±o, etc. ls -r1 | sort | uniq -c | sort -nr permite listar rapidamente archivos duplicados (por nombre) en un directorio y subdirectorios Los parametros no funcionan en Get-ChildItem cd es Change Directory, mapea Set-Directory en Powershell. cd /un/path/especifico cambia a un directorio segun un path directo o relativo cd $VAR dirige a un directorio definido por una variable ambiental, como $HOME cd .. permite subir al directorio superior, como en /home/directory a /home cd - es para volver rapidamente al directorio anterior. Util si cambian rapidamente entre un sub-sub-subdirectorio Los paths usan \\ en Windows. / no funciona mkdir es MaKe DIRectory, mapea a New-Item en Powershell. En *nix podemos crear multiples directorios y subdirectorios como mkdir -p Directorio/{Sub1,Sub2,Sub3} (sin espacios, solo ,) En Powershell necesitamos una sintaxis explicita; ie. mkdir Directorio\\Sub1, Directorio\\Sub2, ... ln,es LiNk, no existe un map directo en Powershell. ln -s &lt;target&gt; &lt;link&gt; permite crear un vinculo -simbolico ln -sf &lt;target&gt; &lt;link&gt; permite actualizar el vinculo simbolico Una opci√≥n en Windows es desempolvar la vieja CMD.exe, y usar MKLINK MKLINK \\D &lt;link&gt; &lt;target&gt; se√±ala un link de \\Directorios Los links son una forma comoda de apuntar a un archivo/directorio especifico que no est√° en nuestro ambiente local. Son comprendidos por el sistema como si el archivo estuviese ahi, a diferencia de un acceso directo. 1.1.2 Descargando archivos curl es C (see) URL, mapeado a Invoke-WebRequest en Powershell. curl &lt;url&gt; -o &lt;archivo&gt; descarga una URL para guardarla en un archivo curl -O &lt;url&gt; descarga la URL a un archvio con su nombre. Usualmente usamos esto wget es Web GET, mapeado a Invoke-WebRequest en Powershell. Es el m√°s facil de usar. wget &lt;url&gt; &lt;url2‚Ä¶&gt; descarga la URL a un archvio con su nombre wget -c &lt;url&gt; permite continuar una descarga interrumpida (muy util para cosas de varios GB) Invoke-WebRequest requiere un output explicito. Invoke-WebRequest &lt;url&gt; -OutFile &lt;archivo&gt; Invoke-WebRequest &lt;url&gt; -Method Get -o &lt;archivo&gt; funciona igual que Wget curl &lt;url&gt; -o &lt;archivo&gt; es valido en Windows base wget &quot;https://pseudo-dropbox.s3-us-west-2.amazonaws.com/Alejandro/baselines.tar.gz&quot; # Descargando un ejemplo 1.1.3 Descomprimiendo archivos tar, no existe en Windows. ‚Ä¶ xf ‚Ä¶ son parametros para eXtract y File tar xf &lt;tar.gz.bz2.xz&gt; desempaca un tar (comprimido) al directorio local tar xf &lt;tar.gz.bz2.xz&gt; -C &lt;directorio&gt; desempaca el tar a un directorio especifico Los tar por defecto no est√°n comprimidos. Un tar.gz si lo est√°. tar cf &lt;nuevo.tar&gt; &lt;archivo1 directorio/*&gt; crea un archivo tar. tar cgf &lt;nuevo.tar.gz&gt; &lt;archivo1 directorio/*&gt; crea un archivo tar comprimido. unzip, no existe en Windows. unzip &lt;zip&gt; extrae los contenidos de un zip en el directorio actual unzip &lt;zip&gt; -d &lt;directorio&gt; extrae el zip a una carpeta especifica zip -r &lt;nuevo.zip&gt; &lt;directorio&gt; comprime un directorio a un zip. Expand-Archive es una utilidad de Windows que funciona como unzip Expand-Archive &lt;zip&gt; &lt;directorio&gt; descomprime un zip en un directorio existente o nuevo Compress-Archive -Path &lt;directorio\\*&gt; -DestinationPath &lt;nuevo.zip&gt; crea un zip con los contenidos de directorio 7zip tiene linea de comandos para Linux, Mac, Windows. tar xf baselines.tar.gz 1.1.4 Explorando y renombrando archivos cat es conCATenate, mapeado a Get-Content en Powershell. cat &lt;archivo&gt; pasa los contenidos de archivo a la terminal, mostrandolos cat &lt;archivo1&gt; &lt;archivo2&gt; &gt; &lt;nuevo&gt; reemplaza los contenidos de nuevo por la concatenaci√≥n de archivo1 y archivo2 cat &lt;achivo3&gt; &gt;&gt; &lt;nuevo&gt; concatena archivo3 a nuevo head, no existe en Windows. head &lt;archivo&gt; muestra las 10 primeras lineas de archivo head -n &lt;archivo&gt; muestra las n primeras lineas de archivo En Windows, Get-Content &lt;archivo&gt; -TotalCount 10 tiene el mismo comportamiento tail, no existe en Windows. tail &lt;archivo&gt; muestra las 10 ultimas lineas de archivo tail -n &lt;archivo&gt; muestra las n ultimas lineas de archivo En Windows, Get-Content &lt;archivo&gt; -Tail 10 tiene el mismo comportamiento cd Ejemplo # Entra al directorio descomprimido cat script.r # Explorando el script 1.2 Lenguajes¬†de¬†programaci√≥n e IDEs 1.2.1 Tipos de lenguajes de programacion Lenguajes de programacion interpretados: son lenguajes en que cada linea es compilada e interpretada en evaluacion, dentro del llamado Read-Eval-Print-Loop (REPL). Esto premite que sean interactivos, dado que cada instruccion devuelve una respuesta inmediata, agilizando significativamente el desarrollo de programas. Python, R, etc. Lenguaje de programacion compilados: a diferencia de un lenguaje interpretado, este es compilado en su totalidad previa ejecucion del programa. Por esto, tienden a ser significativamente mas rapidos en ejecucion, a costa del tiempo de compilacion. C, C++, Fortran, Julia, etc. Lenguaje maquina: representan el nivel m√°s bajo al que el compilador traduce las instrucciones, el denominado codigo binario que opera fisicamente en el procesador. De cierta forma, la brecha entre lenguajes compilados se hace borrosa al considerar que una gran parte de las librerias que usamos en lenguajes interpretados son implementaciones escritas en C/C++, Fotran, u otros lenguajes compilados (ej. la libreria NumPy en Python); y ademas es posible usar compiladores just-in-time (JIT) para funciones de codigo interpretado (ej. Numba en Python, JIT en R). Por el otro lado, existen herramientas que permiten trabajar (casi) linea a linea con lenguajes compilados, como el paquete Pluto para Julia. Lenguaje de marcado: JSON, LaTeX, Markdown son lenguajes que permiten especificar estructuras de documentos. Existen formatos hibridos, como RMD, que incluyen la sintaxis de marcado de Markdown junto a la posibilidad de ejecutar codigo en R. El principal proposito de los RMD es que pueden ser compilados a documentos como informes, presentaciones, esta misma documentaci√≥n, etc. usando el paquete knitr para exportarlos a formato HTML, Word, PDF, etc. Por esto incluyen una gram√°tica de escritura simple y moderna, sin cosas como \\' para tildes. Los RMD no son programas, pero pueden ser usados como si lo fueran, por ejemplo en una pipeline de procesamiento dentro de un cluster de computo. Como la mezcla de texto plano y codigo puede hacerlos confusos, es recomendable que usen programas .r en lugar de cuadernos .rmd para este tipo de cosas. Cabe mencionar que el lenguaje de las SHELL puede ser considerado como un lenguaje interpretado, dado que ejecuta instrucciones de forma lineal aunque comunmente estas son llamar a programas ya compilados. 1.2.2 Integrated Development Environment Un IDE es comunmente una aplicaci√≥n con una interfaz R Studio fue originalmente creado para trabajar con R, pero actualmente es capaz de trabajar con multiples otros lenguajes como Python o BASH script directamente, apuntando a ser un entorno completo para datascience. VS Code es originalmente un editor de texto, pero cuenta con extensiones que facilmente lo convierten en un IDE poliglota para trabajar con R, Python, C, Julia, y casi cualquier lenguaje existente. Permite trabajar interactivamente con codigo R y Python La extensi√≥n LiveShare permite trabajar con colaboradores en tiempo real, a la Google Docs La extensi√≥n Remotes-SSH permite conectarlo a un entorno en otra maquina f√≠sica, lo cual es √∫til para trabajar en sistemas como un cluster HPC Jupyter es un entorno para trabajar con cuadernos, originalmente en Python pero ahora con m√∫ltiples interpretes como R o Julia. Dado que corre en un servidor y presenta una interfaz web, es com√∫nmente usado conectado a un backend mas potente que el computador del usuario. Se puede usar en Google Colab. La versi√≥n mas moderna es Jupyter Lab, que incluye funciones como m√∫ltiples pesta√±as, terminales, etc. Los cuadernos son f√°ciles de usar, pero el c√≥digo subyacente es un h√≠brido de Python y JSON para cada celda. Esto los hace mucho mas propensos a errores de replicabilidad, dado que un cambio en una celda NO afecta a las otras a menos que estas se corran de nuevo o se reinicie el Kernel. Aparte, sin Jupyter para mostrar los archivos, es complicado leer el codigo JSON y entender que hace el programa. 1.3 Introducci√≥n a R y cuadernos 1.3.1 Formato de R notebooks La sintaxis de R permite que el codigo sea legible para personas, y es posible a√±adir comentarios explicativos como # comentario. A√∫n as√≠, para un documento t√©cnico es necesaria m√°s informaci√≥n, como figuras, texto en italica, etc. Los cuadernos con extensi√≥n .Rmd permiten tomar notas m√°s largas, y aplicar formato como utilizando sintaxis Markdown, con algunas modificaciones. _ italica ** negrita ` monoespaciado Podemos a√±adir # al inicio de una linea para marcarla como titulo, sub-titulo, sub-sub-titulo, etc‚Ä¶ para as√≠ hacer un esquema m√°s ordenado. 1.3.2 Trabajando con chunks Los cuadernos seccionan el codigo en chunks, o secciones cortas de codigo. Podemos darles nombre de forma ```{r NOMBRE DEL CHUNK} Estas secciones luego pueden ejecutarse cada una como su propio script, accediendo a variables dejadas por las otras secciones. Por ejemplo, haciendo una definici√≥n de los tipos de objetos en R: A &lt;- 15.0 # N√∫mero B &lt;- 15e2 # N√∫mero en notaci√≥n cient√≠fica C &lt;- pi # Constantes definidas D &lt;- &#39;cadena de texto&#39; # Texto E &lt;- FALSE # Valores binarios M√°s otros objetos: V &lt;- c(1, 3, 5) # Un vector W &lt;- 7:9 # Otro vector, naturales desde 7 a 9 X &lt;- list(V, x &lt;- 2, &quot;texto&quot;) # Una lista, con distintos tipos de objetos con nombre Y &lt;- data.frame(V, W, c(7,8,9)) # Una lista con elementos del mismo largo # son m√°s complejos, y los veremos en detalle Estos dos chunks son independientes, por lo que podriamos modificarlos sin que se afecten entre si. Podemos usar los objetos creados en estos chunks fuera, en otros chunks del cuaderno: V*A # Multiplicando un vector (1,2,5) por un escalar (15) ## [1] 15 45 75 Luego, podemos usar el header del chunk (donde esta el nombre) para controlar otros atributos, como las salidas, warnings, o ejecuci√≥n del chunk. Un chunk sin ejecuci√≥n autom√°tica puede usarse para cargar las librer√≠as al inicio de la clase, dado que luego no necesario recargarlas durante la sesi√≥n. library(tidyverse) # Set de paquetes que hacen muchas cosas library(gapminder) # data de Gapminder library(gifski) # encoding de GIFs library(webshot) # screenshots de paginas web library(ggplot2) # Gr√°ficos complejos library(GGally) # extensi√≥n de ggplot2 library(ggsci) # paletas de colores para publicaci√≥n library(gganimate) # gr√°ficos animados library(ggmuller) # diagrama de evolucionarios Muller library(autoplotly) # visualizaciones interactivas library(gridExtra) # extensi√≥n de grid, para la creaci√≥n de figuras 1.4 Importaci√≥n y analisis de datos Podemos descargar datasets desde sitios publicos usando programas de la terminal, como wget wget https://pseudo-dropbox.s3-us-west-2.amazonaws.com/Alejandro/baselines.tar.gz wget https://pseudo-dropbox.s3-us-west-2.amazonaws.com/Alejandro/baseline.csv ## --2021-04-30 06:05:16-- https://pseudo-dropbox.s3-us-west-2.amazonaws.com/Alejandro/baselines.tar.gz ## Resolving pseudo-dropbox.s3-us-west-2.amazonaws.com (pseudo-dropbox.s3-us-west-2.amazonaws.com)... 52.218.246.177, 52.218.229.169 ## Connecting to pseudo-dropbox.s3-us-west-2.amazonaws.com (pseudo-dropbox.s3-us-west-2.amazonaws.com)|52.218.246.177|:443... connected. ## HTTP request sent, awaiting response... 200 OK ## Length: 368703 (360K) [application/x-tar] ## Saving to: ‚Äòbaselines.tar.gz‚Äô ## ## 0K .......... .......... .......... .......... .......... 13% 256K 1s ## 50K .......... .......... .......... .......... .......... 27% 266K 1s ## 100K .......... .......... .......... .......... .......... 41% 287K 1s ## 150K .......... .......... .......... .......... .......... 55% 2.49M 0s ## 200K .......... .......... .......... .......... .......... 69% 6.43M 0s ## 250K .......... .......... .......... .......... .......... 83% 291K 0s ## 300K .......... .......... .......... .......... .......... 97% 5.12M 0s ## 350K .......... 100% 15.5M=0.8s ## ## 2021-04-30 06:05:18 (469 KB/s) - ‚Äòbaselines.tar.gz‚Äô saved [368703/368703] ## ## --2021-04-30 06:05:18-- https://pseudo-dropbox.s3-us-west-2.amazonaws.com/Alejandro/baseline.csv ## Resolving pseudo-dropbox.s3-us-west-2.amazonaws.com (pseudo-dropbox.s3-us-west-2.amazonaws.com)... 52.218.201.105, 52.218.229.169 ## Connecting to pseudo-dropbox.s3-us-west-2.amazonaws.com (pseudo-dropbox.s3-us-west-2.amazonaws.com)|52.218.201.105|:443... connected. ## HTTP request sent, awaiting response... 200 OK ## Length: 206369 (202K) [text/csv] ## Saving to: ‚Äòbaseline.csv‚Äô ## ## 0K .......... .......... .......... .......... .......... 24% 245K 1s ## 50K .......... .......... .......... .......... .......... 49% 237K 0s ## 100K .......... .......... .......... .......... .......... 74% 1.03M 0s ## 150K .......... .......... .......... .......... .......... 99% 311K 0s ## 200K . 100% 2922G=0.6s ## ## 2021-04-30 06:05:20 (323 KB/s) - ‚Äòbaseline.csv‚Äô saved [206369/206369] El archivo baselines.tar.gz es un comprimido, por lo que es necesario abrirlo con tar, desde la terminal. tar xf baselines.tar.gz Finalmente, importar los archivos descargados a la sesi√≥n de R. library(tidyverse) library(readxl) baseline_csv &lt;- read_csv(&quot;baseline.csv&quot;) baseline_tsv &lt;- read_tsv(&quot;baseline.tsv&quot;) baseline_xlsx &lt;- read_excel(&quot;baseline.xlsx&quot;) Viendo el contenido de uno de estos archivos head( baseline_csv ) ## # A tibble: 6 x 10 ## X1 harmonic_central‚Ä¶ eigenvector_cent‚Ä¶ betweenness_cent‚Ä¶ closeness_centr‚Ä¶ ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 DM_10f‚Ä¶ 223. 0.00000739 0 0.189 ## 2 DM_10f‚Ä¶ 223. 0.00000739 0 0.189 ## 3 DM_10f‚Ä¶ 223. 0.00000370 0 0.189 ## 4 DM_5thf 224. 0.00000741 0 0.190 ## 5 DM_6dhf 223. 0.00000739 0 0.189 ## 6 DM_6thf 223. 0.00000739 0 0.189 ## # ‚Ä¶ with 5 more variables: load_centrality &lt;dbl&gt;, information_centrality &lt;dbl&gt;, ## # communicability_betweenness_centrality &lt;dbl&gt;, katz_centrality_numpy &lt;dbl&gt;, ## # pagerank &lt;dbl&gt; "],["clase-2-creaci√≥n-y-exploraci√≥n-de-estructuras-de-datos.html", "2 CLASE 2 - Creaci√≥n y exploraci√≥n de estructuras de datos 2.1 Creaci√≥n de dataframes 2.2 Descargando data desde internet 2.3 Leyendo archivos extra√±os 2.4 Directorios en R", " 2 CLASE 2 - Creaci√≥n y exploraci√≥n de estructuras de datos 2.1 Creaci√≥n de dataframes 2.2 Descargando data desde internet 2.2.1 Descarga desde p√°gina web R cuenta con multiples metodos para descargar archivos. El paquete utils usa programas del sistema como metodos para download.file(), como curl, wget, wininet, etc. los cuales pueden no estar instalados en el sistema. Por ejemplo, download.file(URL, method = \"wget\") usualmente falla en Windows. Especificando otro metodo, download.file(URL, method = \"libcurl\") funciona. Podemos descargar datasets directamente desde R, lo cual resulta util a la hora de evaluar data de publicaciones presente como Informaci√≥n suplementaria. library(readxl) # Data suplementaria bonita suplementaria.url &lt;- &quot;https://www.pnas.org/highwire/filestream/794560/field_highwire_adjunct_files/0/pnas.1800165115.sd01.xlsx&quot; destfile &lt;- &quot;sup_bonita.xlsx&quot; #Para LINUX usar: download.file(url= suplementaria.url, destfile= &#39;sup_bonita.xlsx&#39;, method = &quot;wget&quot;) #Para WINDOWS usar: download.file(url= suplementaria.url, destfile= &#39;sup_bonita.xlsx&#39;, method = &quot;libcurl&quot;) suplementaria.bonita &lt;- read_excel( &quot;sup_bonita.xlsx&quot; ) suplementaria.bonita ## # A tibble: 368 x 11 ## GeneID `Entrez Gene Na‚Ä¶ P7MeanFPKM P32MeanFPKM `10wkMeanFPKM` `9.5mMeanFPKM` ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Ctss cathepsin S 0.59 1.13 3.03 8.32 ## 2 Oasl2 2&#39;-5&#39; oligoaden‚Ä¶ 1.06 3.37 3.70 36.1 ## 3 Zc3hav1 zinc finger CCC‚Ä¶ 0.58 1.42 1.53 6.84 ## 4 Ggta1 glycoprotein ga‚Ä¶ 1.65 0.993 1.04 4.89 ## 5 Lyz2 lysozyme 1.01 1.44 3.46 4.57 ## 6 Ifit1 interferon-indu‚Ä¶ 0.773 2.08 2.12 13 ## 7 Tyrobp TYRO protein ty‚Ä¶ 3.06 4.73 3.33 4.15 ## 8 C4b complement comp‚Ä¶ 1.37 7.39 8.02 23.1 ## 9 Wdfy1 WD repeat and F‚Ä¶ 10.3 4.07 1.36 1.65 ## 10 Osmr oncostatin M re‚Ä¶ 6.49 6.40 4.52 13.3 ## # ‚Ä¶ with 358 more rows, and 5 more variables: 2yrMeanFPKM &lt;dbl&gt;, log2 FC &lt;dbl&gt;, ## # logCPM &lt;dbl&gt;, PValue &lt;dbl&gt;, FDR &lt;dbl&gt; 2.2.2 Descarga desde GitHub GitHub es un servicio de repositorios para control de versiones de codigo basado en Git. Actualmente es la plataforma m√°s popular para hosting del codigo de software, con proyectos como RStudio, el catalogo de cursos de FreeCodeCamp, este mismo curso, etc. Muchos proyectos de ciencia abierta, ciencia ciudadana, y cada vez m√°s publicaciones ponen la data a disposici√≥n de la comunidad; con el mismo historial de versiones que el codigo usado para generar y analizar dicha data. El Ministerio de Ciencia de Chile dispone la data de Coronavirus como tablas CSV facilmente descargables desde un repositorio en Github. Por ejemplo, la data de examenes PCR tomados por region. library(readr) github.url &lt;- &quot;https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto7/PCR.csv&quot; # Direcci√≥n del dataset publico MINCIENCIA_PCR &lt;- read_csv( github.url ) # Podemos leer los archivos directamente MINCIENCIA_PCR ## # A tibble: 16 x 389 ## Region `Codigo region` Poblacion `2020-04-09` `2020-04-10` `2020-04-11` ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Arica y Par‚Ä¶ 15 252110 70 NA 93 ## 2 Tarapac√° 01 382773 NA NA NA ## 3 Antofagasta 02 691854 182 128 107 ## 4 Atacama 03 314709 57 52 60 ## 5 Coquimbo 04 836096 NA NA NA ## 6 Valpara√≠so 05 1960170 301 249 248 ## 7 Metropolita‚Ä¶ 13 8125072 5383 3185 2105 ## 8 O‚ÄôHiggins 06 991063 68 NA 74 ## 9 Maule 07 1131939 397 219 NA ## 10 √ëuble 16 511551 364 NA 259 ## 11 Biob√≠o 08 1663696 592 149 281 ## 12 Araucan√≠a 09 1014343 124 148 126 ## 13 Los R√≠os 14 405835 NA 91 NA ## 14 Los Lagos 10 891440 341 199 178 ## 15 Ays√©n 11 107297 10 NA NA ## 16 Magallanes 12 178362 73 24 46 ## # ‚Ä¶ with 383 more variables: 2020-04-12 &lt;dbl&gt;, 2020-04-13 &lt;dbl&gt;, ## # 2020-04-14 &lt;dbl&gt;, 2020-04-15 &lt;dbl&gt;, 2020-04-16 &lt;dbl&gt;, 2020-04-17 &lt;dbl&gt;, ## # 2020-04-18 &lt;dbl&gt;, 2020-04-19 &lt;dbl&gt;, 2020-04-20 &lt;dbl&gt;, 2020-04-21 &lt;dbl&gt;, ## # 2020-04-22 &lt;dbl&gt;, 2020-04-23 &lt;dbl&gt;, 2020-04-24 &lt;dbl&gt;, 2020-04-25 &lt;dbl&gt;, ## # 2020-04-26 &lt;dbl&gt;, 2020-04-27 &lt;dbl&gt;, 2020-04-28 &lt;dbl&gt;, 2020-04-29 &lt;dbl&gt;, ## # 2020-04-30 &lt;dbl&gt;, 2020-05-01 &lt;dbl&gt;, 2020-05-02 &lt;dbl&gt;, 2020-05-03 &lt;dbl&gt;, ## # 2020-05-04 &lt;dbl&gt;, 2020-05-05 &lt;dbl&gt;, 2020-05-06 &lt;dbl&gt;, 2020-05-07 &lt;dbl&gt;, ## # 2020-05-08 &lt;dbl&gt;, 2020-05-09 &lt;dbl&gt;, 2020-05-10 &lt;dbl&gt;, 2020-05-11 &lt;dbl&gt;, ## # 2020-05-12 &lt;dbl&gt;, 2020-05-13 &lt;dbl&gt;, 2020-05-14 &lt;dbl&gt;, 2020-05-15 &lt;dbl&gt;, ## # 2020-05-16 &lt;dbl&gt;, 2020-05-17 &lt;dbl&gt;, 2020-05-18 &lt;dbl&gt;, 2020-05-19 &lt;dbl&gt;, ## # 2020-05-20 &lt;dbl&gt;, 2020-05-21 &lt;dbl&gt;, 2020-05-22 &lt;dbl&gt;, 2020-05-23 &lt;dbl&gt;, ## # 2020-05-24 &lt;dbl&gt;, 2020-05-25 &lt;dbl&gt;, 2020-05-26 &lt;dbl&gt;, 2020-05-27 &lt;dbl&gt;, ## # 2020-05-28 &lt;dbl&gt;, 2020-05-29 &lt;dbl&gt;, 2020-05-30 &lt;dbl&gt;, 2020-05-31 &lt;dbl&gt;, ## # 2020-06-01 &lt;dbl&gt;, 2020-06-02 &lt;dbl&gt;, 2020-06-03 &lt;dbl&gt;, 2020-06-04 &lt;dbl&gt;, ## # 2020-06-05 &lt;dbl&gt;, 2020-06-06 &lt;dbl&gt;, 2020-06-07 &lt;dbl&gt;, 2020-06-08 &lt;dbl&gt;, ## # 2020-06-09 &lt;dbl&gt;, 2020-06-10 &lt;dbl&gt;, 2020-06-11 &lt;dbl&gt;, 2020-06-12 &lt;dbl&gt;, ## # 2020-06-13 &lt;dbl&gt;, 2020-06-14 &lt;dbl&gt;, 2020-06-15 &lt;dbl&gt;, 2020-06-16 &lt;dbl&gt;, ## # 2020-06-17 &lt;dbl&gt;, 2020-06-18 &lt;dbl&gt;, 2020-06-19 &lt;dbl&gt;, 2020-06-20 &lt;dbl&gt;, ## # 2020-06-21 &lt;dbl&gt;, 2020-06-22 &lt;dbl&gt;, 2020-06-23 &lt;dbl&gt;, 2020-06-24 &lt;dbl&gt;, ## # 2020-06-25 &lt;dbl&gt;, 2020-06-26 &lt;dbl&gt;, 2020-06-27 &lt;dbl&gt;, 2020-06-28 &lt;dbl&gt;, ## # 2020-06-29 &lt;dbl&gt;, 2020-06-30 &lt;dbl&gt;, 2020-07-01 &lt;dbl&gt;, 2020-07-02 &lt;dbl&gt;, ## # 2020-07-03 &lt;dbl&gt;, 2020-07-04 &lt;dbl&gt;, 2020-07-05 &lt;dbl&gt;, 2020-07-06 &lt;dbl&gt;, ## # 2020-07-07 &lt;dbl&gt;, 2020-07-08 &lt;dbl&gt;, 2020-07-09 &lt;dbl&gt;, 2020-07-10 &lt;dbl&gt;, ## # 2020-07-11 &lt;dbl&gt;, 2020-07-12 &lt;dbl&gt;, 2020-07-13 &lt;dbl&gt;, 2020-07-14 &lt;dbl&gt;, ## # 2020-07-15 &lt;dbl&gt;, 2020-07-16 &lt;dbl&gt;, 2020-07-17 &lt;dbl&gt;, 2020-07-18 &lt;dbl&gt;, ## # 2020-07-19 &lt;dbl&gt;, 2020-07-20 &lt;dbl&gt;, ‚Ä¶ Es importante notar que esta esta en raw.githubusercontent‚Ä¶, lo cual seria distinto a https://github.com/MinCiencia/Datos-COVID19/blob/master/output/producto7/PCR.csv , que es donde llegamos explorando el repo metiante links. https://github.com/ muestra la data con opciones como un historial de cambios y un README.md, pero es una pagina web completa https://raw.githubusercontent.com/ tiene el archivo de data puro que queremos descargar library(tidyverse) MINCIENCIA_PCR$Region -&gt; my_col_names MINCIENCIA_PCR %&gt;% select(contains(&#39;20&#39;)) -&gt; only_dates only_dates %&gt;% t %&gt;% as.data.frame() %&gt;% set_names(my_col_names) -&gt; my_data my_data %&gt;% rownames_to_column(&quot;Fecha&quot;) %&gt;% pivot_longer(!Fecha, names_to = &quot;Regi√≥n&quot;, values_to = &quot;Tests&quot;) -&gt; my_data_for_plot p1 &lt;- ggplot(my_data_for_plot, aes(x = Fecha, y = Tests)) + geom_point(shape = 4) p1 p1+ scale_y_log10() -&gt; p2 p2 p1+ scale_y_log10() -&gt; p2 p2 p2 + labs(x = &quot;Tiempo (d√≠as)&quot;, y = &quot;N√∫mero de tests PCR&quot;) + theme(axis.ticks = element_blank(), axis.text.x=element_blank()) -&gt; p3 p3 p3+aes( color = Regi√≥n)+ theme(legend.position = &quot;bottom&quot;, legend.box = &quot;horizontal&quot;) -&gt; p4 p4 ggplot(my_data_for_plot, aes(x=Fecha, y = Tests, color = Regi√≥n)) + geom_point( alpha=0.5)+ theme(legend.position = &quot;bottom&quot;, legend.box = &quot;horizontal&quot;)+ scale_y_log10()+ theme(axis.ticks = element_blank(), axis.text.x=element_blank()) + labs(x = &quot;Tiempo (d√≠as)&quot;, y = &quot;N√∫mero de tests PCR&quot;) -&gt; my_plot my_plot ## Warning: Transformation introduced infinite values in continuous y-axis ## Warning: Removed 40 rows containing missing values (geom_point). library(ggthemes) ggplot(my_data_for_plot, aes(x=Regi√≥n, y=Tests, color=Regi√≥n))+geom_bar(stat=&quot;identity&quot;) + theme_economist() + theme(legend.position = &quot;none&quot;, axis.text.x = element_text(angle = 90)) 2.3 Leyendo archivos extra√±os 2.3.1 Escritura de archivos con delimitadores (csv, tsv, txt, etc.) En un archivo de texto plano, denominamos un caracter especifico como delimitador. , en archivos Coma Separated Values ; en archivos CSV que por motivos incluyen comas \\t en archivos Tab Separated Values suele ser un separador comun en archivos de texto o al copiar y pegar desde Excel La funci√≥n readr::read_delim() puede aceptar delimitadores arbitrarios a la hora de leer archivos de texto plano. Esto puede resultar util para tareas como parsear la salida de un programa y generar una tabla informativa. # Output real de un programa de HPC; tira los valores a print() como forma # de mostrar que esta haciendo algo en lugar de estar 10h sin noticias stout &lt;- &quot; (pid=7648)#EX_na1(e)#0.006122665930025846 (pid=7651)#EX_pro-L(e)#0.006122663829443571 (pid=7655)#EX_orn(e)#0.006122663638493012 (pid=7643)#EX_leu-L(e)#0.006122663638095198 (pid=7647)#EX_pyr(e)#0.006122663829665405 (pid=7659)#10FTHF6GLUtm#0.00612267089307223 (pid=7667)#EX_val-L(e)#0.006122663638095198 (pid=7617)#DM_fald#0.006122663638115122 (pid=7618)#DM_ahcys#0.006122663639234617 (pid=7621)#DM_pheme(c)#0.006122663638166545 (pid=7625)#EX_acac(e)#0.00612266382975526 (pid=7627)#EX_asn-L(e)#0.006122663638508968 &quot; log.info &lt;- read_delim( stout , delim= &#39;#&#39; , col_names = FALSE) log.info ## # A tibble: 12 x 3 ## X1 X2 X3 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 (pid=7648) EX_na1(e) 0.00612 ## 2 (pid=7651) EX_pro-L(e) 0.00612 ## 3 (pid=7655) EX_orn(e) 0.00612 ## 4 (pid=7643) EX_leu-L(e) 0.00612 ## 5 (pid=7647) EX_pyr(e) 0.00612 ## 6 (pid=7659) 10FTHF6GLUtm 0.00612 ## 7 (pid=7667) EX_val-L(e) 0.00612 ## 8 (pid=7617) DM_fald 0.00612 ## 9 (pid=7618) DM_ahcys 0.00612 ## 10 (pid=7621) DM_pheme(c) 0.00612 ## 11 (pid=7625) EX_acac(e) 0.00612 ## 12 (pid=7627) EX_asn-L(e) 0.00612 2.3.1.1 Escribiendo DataFrames en Excel Aunque francamente suele ser un dolor de cabeza, es el formato de facto para compartir datos. Por favor, no contribuyan a este problema en el mundo de la ciencia. O al menos hagan Excels con sentido, sin arreglos esotericos de columnas y filas. colnames( log.info ) &lt;- c(&quot;Process ID&quot;,&quot;Node&quot;,&quot;Alpha&quot;) # Pone nombres de columna writexl::write_xlsx( log.info , path = &quot;logs_hpc.xlsx&quot;) # Guarda el Excel 2.3.1.2 Guardando datos en formato RDS y RData R posee formatos propios para guardar datasets, los que tienen la ventaja de conservar propiedades como etiquetas, la estructura, etc; y permitir serializar y comprimir (usando gzip) los datos. Dependiendo de la data, un RDS puede ser 10 veces m√°s peque√±o que un CSV. 2.3.1.3 Listas y serializados En datasets de gran tama√±o, o donde una cantidad significativa de los datos son NaN, es convieniente usar formatos de archivos binarios, es decir, procesados y comprimidos, como un .zip o los archivos R Data Serial .RDS. .RDS son R Data Single, un unico objeto. .RData o .Rda, multiples objetos de R. saveRDS( suplementaria.bonita , &quot;sup_bonita.rds&quot; ) # Pesa 26.1 kB, ~43% el tama√±o del Excel original load(&quot;sub_bonita.rds&quot;) # Usamos load() para cargar los serializados En caso de tener multiples objetos, podemos pasar estos dentro de una lista. Estas son similares a vectores c(), en el sentido de que son objetos ordenados e iterables, paro a diferencia de los vectores, una lista puede contener multiples tipos de objetos, y estos pueden ser objetos complejos en lugar de tipos simples Creamos listas con list(). Podemos guardar objetos como los plots hechos anteriormente. plots &lt;- list( p1, # Fig 1 p2, # Fig 2 p3, # Fig 3 p4 # Fig 4 ) # Y guardamos todos los plots dentro de un RDS saveRDS( plots, &quot;plots.RDS&quot; ) 2.4 Directorios en R Si bien es posible trabajar con todos los codigos, datasets, resultados, resplados y demas en una unica carpeta, esto es lejos de ser agradable. Ejemplo 2.4.1 Generaci√≥n de listas de archivos de los directorios Podemos listar todo lo que hay en un directorio list.files(getwd() , pattern=NULL, all.files=FALSE) ## [1] &quot;_bookdown_files&quot; ## [2] &quot;_bookdown.yml&quot; ## [3] &quot;_output.yml&quot; ## [4] &quot;00-setup&quot; ## [5] &quot;01-intro&quot; ## [6] &quot;02-estructuras-datos&quot; ## [7] &quot;03-mutate-pipes-regex&quot; ## [8] &quot;04-filters-lists-programacion-funcional-apply-map&quot; ## [9] &quot;baseline.csv&quot; ## [10] &quot;baseline.pkl&quot; ## [11] &quot;baseline.tsv&quot; ## [12] &quot;baseline.xlsx&quot; ## [13] &quot;baselines.tar.gz&quot; ## [14] &quot;book.bib&quot; ## [15] &quot;clases_cache&quot; ## [16] &quot;clases_files&quot; ## [17] &quot;clases.Rmd&quot; ## [18] &quot;clases.Rproj&quot; ## [19] &quot;index.Rmd&quot; ## [20] &quot;logs_hpc.xlsx&quot; ## [21] &quot;packages.bib&quot; ## [22] &quot;plots.RDS&quot; ## [23] &quot;README.md&quot; ## [24] &quot;style.css&quot; ## [25] &quot;sup_bonita.xlsx&quot; 2.4.2 Creaci√≥n de directorios y de archivos dentro de R getwd() # Obtiene el directorio de trabajo paste0(getwd(),&#39;/hola&#39;) # Convierte getwkd() a caracter y concatena file.path(getwd(),&#39;hola&#39;) # Hace direcciones independientes del SO file.path(getwd(),&#39;hola&#39;,&#39;cosas&#39;) # Podemos definir sub-directorios "],["clase-3-exploraci√≥n-y-transformaci√≥n-de-estructuras-de-datos-en-r.html", "3 CLASE 3 - Exploraci√≥n y transformaci√≥n de estructuras de datos en R 3.1 Utilizando mutate para manipulaci√≥n de datos 3.2 Pipes complicadas 3.3 Expresiones regulares 3.4 Workflow de la vida real 3.5 Ejemplo de vida real", " 3 CLASE 3 - Exploraci√≥n y transformaci√≥n de estructuras de datos en R library(&quot;tidyverse&quot;) # Muchas cosas cool # Incluidas en tidyverse, en caso de errores cargandolo library(&quot;dplyr&quot;) # Manipulaci√≥n de datos mediante gramatica propia library(&quot;magrittr&quot;) # Operadores ca√±eria (pipes) %&gt;%) library(&quot;readr&quot;) # Traducci√≥n (pharsing) de archivos a una tibble library(&quot;stringr&quot;) # Operadores consistentes para strings La funci√≥n mutate() de dplyr permite crear nuevas variables manteniendo las ya existentes. Por ejemplo, sacando el promedio de dos variables u operaciones similares. # Importando datos de un CSV data.location &lt;- &quot;https://raw.githubusercontent.com/DeepenData/clases/2bd7d93d9f23b2fe3fc679ca44e40a286f292ffe/06_mutate_pipes_regex/data_oct_08_2020.csv&quot; sim.without.outliers &lt;- read_csv(data.location) # Importa la data a &quot;sim.without.outliers&quot; 3.1 Utilizando mutate para manipulaci√≥n de datos 3.1.1 Accediendo a datos tabulados La gramatica de R utiliza [] y $ para acceder a objetos dentro de una estructura de datos. Con un dataframe como el sacado de un CSV, esto son las filas, columnas, celdas individuales, etc. Dado que un dataframe puede contener dataframes, este modo de acceso puede ir varios niveles de profundidad . sim.without.outliers$1 saca la primera como vector sim.without.outliers[1] saca la columna 1 sim.without.outliers[ ,c(1,6)] saca las columnas 1 y 6 sim.without.outliers[ ,c(1:6)] saca las columnas de 1 a 6 sim.without.outliers[ ,-c(1,6)] saca todas las columnas menos la 1 y 6 sim.without.outliers[c(10:110) ,c(2:6)] saca las filas 10 a 110 (100 en total) de las columnas 2 a 6 sim.without.outliers[[1]] Sacamos la columna 1 como vector # Accediendo a data en un objeto sim.without.outliers[c(10:200), -c(1:2)] %&gt;% rowMeans() sim.without.outliers[&quot;treatment_1&quot;] / sim.without.outliers[&quot;treatment_2&quot;] %&gt;% log2() -&gt; hola sim.without.outliers$nueva_columna &lt;- hola # Llena la columna con &quot;hola&quot; sim.without.outliers$nueva_columna &lt;- NULL # Elimina una columna Para trabajar con columnas en un dataframe, usamos dplyr::mutate(). Esto crea una nueva columna a partir de existentes, preservando las originales. # Modificando la tabla con mutate() para calcular el Fold-change (log2/log2) sim.without.outliers %&gt;% # Tirando data por la ca√±eria # Hace un promedio de las columnas TREAT(MENT) mutate(`Mean treatment` = rowMeans(select(., starts_with(&quot;treat&quot;)))) %&gt;% # Hace un promedio de las columnas CONTROL mutate(`Mean control` = rowMeans(select(., starts_with(&quot;control&quot;)))) %&gt;% # Calcula el fold-change de TRATAMIENTO sobre CONTROL mutate(`log2Ratio` = log2(.[[&quot;Mean treatment&quot;]] / .[[&quot;Mean control&quot;]])) -&gt; mutated.sim 3.1.2 Funciones personalizadas Creamos funciones para evitar escribir miles de lineas de codigo cada vez que queremos repetir algo. Podemos agruparlas y hacer una libreria para proyectos grandes, donde reutilizamos las funciones, o para recursiones. Es importante considerar que las funciones son para cosas con un comportamiento predecible, e idealmente estable. Para analisis de datos, usualmente tenemos que limpiar los datasets, para tener una estructura ‚Äúest√°ndar‚Äù que nuestras funciones acepten, e idealmente definir un comportamiento de error para las funciones. # Creamos funciones personalizadas para reutilizar codigo # Aumenta por el cambio +- fracci√≥n del cambio. Es decir 3 +- 0.3 (2.7-3.3) an.increase &lt;- function(x, change = 3, fraction = .1) { runif(1, min = (change * x - fraction * (change * x)), max = (change * x + fraction * (change * x))) } # Disminuye por el cambio +- fracci√≥n del cambio. Es decir 0.2 +- 0.1 (0.1-0.3) a.decrease &lt;- function(x, change = .2, fraction = .1) { runif(1, min = (change * x - fraction * (change * x)), max = (change * x + fraction * (change * x))) } Podemos crear una funci√≥n para el pipeline m√°s complejo que hicimos para el calculo del fold-change. generate_mean_log2Ratio &lt;- function(x, a.letter) { x %&gt;% mutate(`Mean treatment` = rowMeans(select(., starts_with(&quot;treat&quot;)))) %&gt;% mutate(`Mean control` = rowMeans(select(., starts_with(&quot;control&quot;)))) %&gt;% mutate(log2Ratio = log2(.[[&quot;Mean treatment&quot;]] / .[[&quot;Mean control&quot;]])) %&gt;% # Les a√±adiremos un identidicador al final, por &quot;&quot;&quot;motivos&quot;&quot;&quot; (ver luego) rename_at(vars(matches(&quot;^treat|^contr|^mean|log2&quot;, ignore.case = TRUE)), funs(paste0(., a.letter))) } # Generando sets para correlaciones sim.without.outliers %&gt;% generate_mean_log2Ratio(&quot; A&quot;) -&gt; A # Calcula el fold-change inicial sin cambios sim.without.outliers %&gt;% mutate(across(starts_with(&quot;treatment&quot;), an.increase)) %&gt;% generate_mean_log2Ratio(&quot; B&quot;) -&gt; B # Fold-change aumenta 1.4-1.7 veces sim.without.outliers %&gt;% mutate(across(starts_with(&quot;treatment&quot;), a.decrease)) %&gt;% generate_mean_log2Ratio(&quot; C&quot;) -&gt; C # Fold-change disminuye -3.3 - -1.7 veces # Creando el dataset final cbind( A, # Parte con la data A select(B, matches(&quot;tre|con|log&quot;)), # A√±ade columnas de B select(C, matches(&quot;tre|con|log&quot;)) ) -&gt; final.data # A√±ade columnas de C y guarda ## name ID treatment_1 A treatment_2 A treatment_3 A control_1 A control_2 A ## 1 bg_1 1 98769372 55528721 216372415 70057879 314970404 ## 2 bg_2 2 21576971 15703117 49743142 3431646477 735515564 ## 3 bg_3 3 574350430 1537885240 8727327947 254444555 11764283 ## 4 bg_4 4 20926171 47644294 88937903 599913422 43731828 ## 5 bg_5 5 164374922 728256656 68959572 495906095 1510632311 ## control_3 A Mean treatment A Mean control A log2Ratio A treatment_1 B ## 1 4478205827 123556836 1621078037 -3.713707 322326623 ## 2 24453279 29007743 1397205107 -5.589962 322326623 ## 3 53031820 3613187872 106413553 5.085518 322326623 ## 4 297274234 52502790 313639828 -2.578643 322326623 ## 5 417270587 320530383 807936331 -1.333780 322326623 ## treatment_2 B treatment_3 B control_1 B control_2 B control_3 B ## 1 151905053 649170201 70057879 314970404 4478205827 ## 2 151905053 649170201 3431646477 735515564 24453279 ## 3 151905053 649170201 254444555 11764283 53031820 ## 4 151905053 649170201 599913422 43731828 297274234 ## 5 151905053 649170201 495906095 1510632311 417270587 ## Mean treatment B Mean control B log2Ratio B treatment_1 C treatment_2 C ## 1 374467292 1621078037 -2.1140419 19765556 11931499 ## 2 374467292 1397205107 -1.8996322 19765556 11931499 ## 3 374467292 106413553 1.8151578 19765556 11931499 ## 4 374467292 313639828 0.2557309 19765556 11931499 ## 5 374467292 807936331 -1.1094019 19765556 11931499 ## treatment_3 C control_1 C control_2 C control_3 C Mean treatment C ## 1 44547260 70057879 314970404 4478205827 25414771 ## 2 44547260 3431646477 735515564 24453279 25414771 ## 3 44547260 254444555 11764283 53031820 25414771 ## 4 44547260 599913422 43731828 297274234 25414771 ## 5 44547260 495906095 1510632311 417270587 25414771 ## Mean control C log2Ratio C ## 1 1621078037 -5.995142 ## 2 1397205107 -5.780733 ## 3 106413553 -2.065943 ## 4 313639828 -3.625370 ## 5 807936331 -4.990502 3.2 Pipes complicadas 3.2.1 Tipos de Pipes Las funciones de pipes vienen mejor definidas en magrittr. R no incluye pipes en base. %&gt;% la pipe tradicional que conocemos y amamos; pasa un obejeto a la entrada de la funci√≥n %$% permite pasar adicionalmente los nombres del objeto %&lt;&gt;% pipe bidireccional, que sirve para modificar el objeto de la entrada %T% una tee, que permite sacar muestras del pipeline, o derivar a otros pipes final.data %$% name %&gt;% head() # Sin head el output es de 3300 cosas ## [1] &quot;bg_1&quot; &quot;bg_2&quot; &quot;bg_3&quot; &quot;bg_4&quot; &quot;bg_5&quot; &quot;bg_6&quot; final.data %$% cor(`log2Ratio A`, `log2Ratio B`) # Correlaci√≥n entre A y B ## [1] 0.7043315 final.data %$% cbind(`log2Ratio A`, `log2Ratio B`, `log2Ratio C`) %&gt;% colSums() -&gt; my.col.sum my.col.sum %&gt;% subset(. &gt; 0) -&gt; my.col.sum my.col.sum %&lt;&gt;% subset(. &gt; 0) # Pipe bidireccional util para actualizar cosas final.data %&gt;% select(matches(&quot;log2&quot;)) %T&gt;% plot() %&gt;% # %T% permite sacar &quot;muestras&quot; del pipe select(matches(&quot;B|C&quot;)) -&gt; my.cols 3.2.2 Usando sistemas de identificadores # Esto crea las descripciones del sistema o como estan descritas # Molestias de los datos √≥micos my.terms &lt;- c(&quot;system 1&quot;, &quot;system 2.7.9&quot;, &quot;subsystem A&quot;, &quot;subsystem B and A&quot;) # Sistemas super-sistemicos sample(my.terms, nrow(final.data) / 2, replace = T) -&gt; terms.col # Genera una columna de terminos de 1650 lineas . sample(final.data$name, nrow(final.data) / 2, replace = F) -&gt; names.sample # saca 1650 nombres sin duplicados, para una tabla donde habran termiminos para sistemas de identificadores data.frame(terms.col, names.sample) -&gt; my.info # hacemos una tabla con datos de multiples funciones inner_join(final.data, my.info, by = c(&quot;name&quot; = &quot;names.sample&quot;)) -&gt; final.data.with.terms # elimina los datos que no tienen los terminos de sistemas que usamos full_join(final.data, my.info, by = c(&quot;name&quot; = &quot;names.sample&quot;)) -&gt; final.data.with.terms.nas # terminos en que algunos tienen descriptores y otros no 3.2.3 Filtrado de filas final.data.with.terms.nas %&gt;% # Nuestra data media sucia sin los nombres sistemicos filter(`log2Ratio A` &lt; 0 &amp; `log2Ratio B` &lt; 0 &amp; `log2Ratio C` &lt; 0) %&gt;% # TODO: porque no funciona con &quot;? drop_na() # Elimina todas las filas con NA # CHUNK SIN OUTPUT 3.3 Expresiones regulares Las expresiones regulares, regex, son (generalizadamente) patrones de texto que definen un criterio de busqeda en un string. Por ejemplo, a... se referiria a cualquier string que sea ‚Äúa‚Äù seguido por tres caracteres, como ‚Äúaaaa,‚Äù ‚Äúa123,‚Äù ‚Äúa,‚Äù etc. Diversos lenguajes usan distintas gramaticas de regex, pero en general usan los mismos comodines y expresiones base. R incluye paquetes base que usan regex, pero stringr tiene funciones m√°s detalladas. Sitios como regex101 permiten testear y analizar expresiones regulares. # Detectando un patron final.data.with.terms.nas %&gt;% .[[&quot;name&quot;]] %&gt;% str_detect(&quot;DE&quot;) %&gt;% # Detecta si hay o no, tira un vectro booleano which() # Tira una lista de las columnas donde es str_detect es TRUE # TODO: que hacia any()? final.data.with.terms.nas %&gt;% .[[&quot;name&quot;]] %&gt;% str_detect(&quot;DE&quot;) %&gt;% any() ## [1] TRUE final.data.with.terms.nas %&gt;% .[[&quot;name&quot;]] %&gt;% str_extract(&quot;DE.\\\\d+&quot;) %&gt;% .[!is.na(.)] # CHUNK SIN OUTPUT # Detecci√≥n de patrones algo m√°s avanzada final.data.with.terms.nas %&gt;% .[[&quot;name&quot;]] %&gt;% str_extract(&quot;[aA-zZ]E.1\\\\d$&quot;) %&gt;% .[!is.na(.)] ## [1] &quot;DE_10&quot; &quot;DE_11&quot; &quot;DE_12&quot; &quot;DE_13&quot; &quot;DE_14&quot; &quot;DE_15&quot; &quot;DE_16&quot; &quot;DE_17&quot; &quot;DE_18&quot; ## [10] &quot;DE_19&quot; final.data.with.terms.nas %&gt;% .[[&quot;name&quot;]] %&gt;% str_extract(&quot;[aA-zZ]E.1\\\\d+&quot;) %&gt;% .[!is.na(.)] ## [1] &quot;DE_10&quot; &quot;DE_11&quot; &quot;DE_12&quot; &quot;DE_13&quot; &quot;DE_14&quot; &quot;DE_15&quot; &quot;DE_16&quot; &quot;DE_17&quot; ## [9] &quot;DE_18&quot; &quot;DE_19&quot; &quot;DE_100&quot; &quot;DE_101&quot; &quot;DE_102&quot; &quot;DE_103&quot; &quot;DE_104&quot; &quot;DE_105&quot; ## [17] &quot;DE_106&quot; &quot;DE_107&quot; &quot;DE_108&quot; &quot;DE_109&quot; &quot;DE_110&quot; &quot;DE_111&quot; &quot;DE_112&quot; &quot;DE_113&quot; ## [25] &quot;DE_114&quot; &quot;DE_115&quot; &quot;DE_116&quot; &quot;DE_117&quot; &quot;DE_118&quot; &quot;DE_119&quot; &quot;DE_120&quot; &quot;DE_121&quot; ## [33] &quot;DE_122&quot; &quot;DE_123&quot; &quot;DE_124&quot; &quot;DE_125&quot; &quot;DE_126&quot; &quot;DE_127&quot; &quot;DE_128&quot; &quot;DE_129&quot; ## [41] &quot;DE_130&quot; &quot;DE_131&quot; &quot;DE_132&quot; &quot;DE_133&quot; &quot;DE_134&quot; &quot;DE_135&quot; &quot;DE_136&quot; &quot;DE_137&quot; ## [49] &quot;DE_138&quot; &quot;DE_139&quot; &quot;DE_140&quot; &quot;DE_141&quot; &quot;DE_142&quot; &quot;DE_143&quot; &quot;DE_144&quot; &quot;DE_145&quot; ## [57] &quot;DE_146&quot; &quot;DE_147&quot; &quot;DE_148&quot; &quot;DE_149&quot; &quot;DE_150&quot; &quot;DE_151&quot; &quot;DE_152&quot; &quot;DE_153&quot; ## [65] &quot;DE_154&quot; &quot;DE_155&quot; &quot;DE_156&quot; &quot;DE_157&quot; &quot;DE_158&quot; &quot;DE_159&quot; &quot;DE_160&quot; &quot;DE_161&quot; ## [73] &quot;DE_162&quot; &quot;DE_163&quot; &quot;DE_164&quot; &quot;DE_165&quot; &quot;DE_166&quot; &quot;DE_167&quot; &quot;DE_168&quot; &quot;DE_169&quot; ## [81] &quot;DE_170&quot; &quot;DE_171&quot; &quot;DE_172&quot; &quot;DE_173&quot; &quot;DE_174&quot; &quot;DE_175&quot; &quot;DE_176&quot; &quot;DE_177&quot; ## [89] &quot;DE_178&quot; &quot;DE_179&quot; &quot;DE_180&quot; &quot;DE_181&quot; &quot;DE_182&quot; &quot;DE_183&quot; &quot;DE_184&quot; &quot;DE_185&quot; ## [97] &quot;DE_186&quot; &quot;DE_187&quot; &quot;DE_188&quot; &quot;DE_189&quot; &quot;DE_190&quot; &quot;DE_191&quot; &quot;DE_192&quot; &quot;DE_193&quot; ## [105] &quot;DE_194&quot; &quot;DE_195&quot; &quot;DE_196&quot; &quot;DE_197&quot; &quot;DE_198&quot; &quot;DE_199&quot; final.data.with.terms.nas %&gt;% .[[&quot;name&quot;]] %&gt;% str_extract(&quot;[aA-zZ]E.1\\\\d.+&quot;) %&gt;% .[!is.na(.)] # CHUNK SIN OUTPUT final.data.with.terms.nas %&gt;% .[[&quot;terms.col&quot;]] %&gt;% str_extract(&quot;^s.*m&quot;) %&gt;% na.exclude() %&gt;% # Es como lo de arriba, pero tira m√°s cosas. Puede ser incomodo sample(10) %&gt;% unique() # CHUNK SIN OUTPUT # Reemplazo de patrones (subsystem -&gt; comparment) # TODO: compartment? final.data.with.terms.nas %&gt;% .[[&quot;terms.col&quot;]] %&gt;% str_replace(&quot;subsyst.*&quot;, &quot;comparment&quot;) %&gt;% na.exclude() %&gt;% sample(10) ## [1] &quot;comparment&quot; &quot;system 2.7.9&quot; &quot;comparment&quot; &quot;system 1&quot; &quot;system 1&quot; ## [6] &quot;system 1&quot; &quot;comparment&quot; &quot;comparment&quot; &quot;comparment&quot; &quot;comparment&quot; 3.4 Workflow de la vida real final.data.with.terms.nas %&gt;% filter(str_detect( name, # en la columna &quot;name&quot; regex(&quot;de.*&quot;, # Busca &quot;de*&quot; ignore_case = T ) ) &amp; # sin diferencias Minuscula/Mayuscula str_detect( terms.col, # Busca en la columna &quot;term.cols&quot; regex(&quot;B.*A&quot;, ignore_case = F) )) # ...terminos que empiezan con B y terminan en A # CHUNK SIN OUTPUT final.data.with.terms.nas %&gt;% filter(str_detect( name, # en la columna &quot;name&quot; regex(&quot;de.*&quot;, # ... el patr√≥n &quot;de*&quot; ignore_case = T ) ) &amp; # sin diferencias Minuscula/Mayuscula str_detect( terms.col, # en la columna &quot;term.cols&quot; regex(&quot;\\\\d.\\\\d&quot;, # ... el patr√≥n &quot;\\\\d.\\\\d&quot; ignore_case = F ) ) &amp; # sin diferencias Minuscula/Mayuscula `log2Ratio C` &lt; 0) %&gt;% # Y el fold-change es menor a 0 select(matches(&quot;log|name|term&quot;)) ## name log2Ratio A log2Ratio B log2Ratio C terms.col ## 1 DE_1 2.88619266 1.72149304 -2.1596075 system 2.7.9 ## 2 DE_9 5.67917488 2.88518017 -0.9959204 system 2.7.9 ## 3 DE_11 3.10021441 0.06300006 -3.8181005 system 2.7.9 ## 4 DE_13 0.82255832 -1.56341118 -5.4445117 system 2.7.9 ## 5 DE_22 -0.76625024 -1.66740167 -5.5485022 system 2.7.9 ## 6 DE_25 1.96060606 -1.01985391 -4.9009545 system 2.7.9 ## 7 DE_36 2.74968692 0.07204354 -3.8090570 system 2.7.9 ## 8 DE_53 -0.58330148 -1.64651798 -5.5276185 system 2.7.9 ## 9 DE_56 4.23552845 2.90516862 -0.9759319 system 2.7.9 ## 10 DE_60 2.73800563 1.63308990 -2.2480107 system 2.7.9 ## 11 DE_64 2.47002415 -0.04970850 -3.9308091 system 2.7.9 ## 12 DE_67 5.58416167 3.54621148 -0.3348891 system 2.7.9 ## 13 DE_75 -0.11981155 -2.20549736 -6.0865979 system 2.7.9 ## 14 DE_81 1.17481419 0.75492764 -3.1261729 system 2.7.9 ## 15 DE_89 0.02689662 -0.49411439 -4.3752149 system 2.7.9 ## 16 DE_91 1.96585394 -1.62345146 -5.5045520 system 2.7.9 ## 17 DE_97 3.80597760 1.42927704 -2.4518235 system 2.7.9 ## 18 DE_98 4.41874115 1.56208028 -2.3190203 system 2.7.9 ## 19 DE_125 5.51197271 2.70544709 -1.1756535 system 2.7.9 ## 20 DE_127 4.76132191 2.22996237 -1.6511382 system 2.7.9 ## 21 DE_129 4.75642719 2.58463855 -1.2964620 system 2.7.9 ## 22 DE_131 4.70996518 1.91561721 -1.9654833 system 2.7.9 ## 23 DE_142 4.84611277 2.47381906 -1.4072815 system 2.7.9 ## 24 DE_148 4.98743782 3.11872663 -0.7623739 system 2.7.9 ## 25 DE_152 4.61256373 1.81066607 -2.0704345 system 2.7.9 ## 26 DE_162 4.30961154 3.53035247 -0.3507481 system 2.7.9 ## 27 DE_181 4.50450193 1.75608264 -2.1250179 system 2.7.9 ## 28 DE_191 2.01897497 1.95532209 -1.9257785 system 2.7.9 ## 29 DE_210 1.96482442 1.98761723 -1.8934833 system 2.7.9 ## 30 DE_215 1.57229716 1.17189052 -2.7092100 system 2.7.9 ## 31 DE_218 4.54997067 2.70319279 -1.1779078 system 2.7.9 ## 32 DE_228 6.03492708 3.60861795 -0.2724826 system 2.7.9 ## 33 DE_230 3.05837416 1.28174575 -2.5993548 system 2.7.9 ## 34 DE_232 4.27065106 1.72458820 -2.1565124 system 2.7.9 ## 35 DE_234 3.90509509 3.39649548 -0.4846051 system 2.7.9 ## 36 DE_239 2.74954208 -0.68467005 -4.5657706 system 2.7.9 ## 37 DE_243 6.61981075 2.82114359 -1.0599570 system 2.7.9 ## 38 DE_255 0.00565650 -1.68945866 -5.5705592 system 2.7.9 ## 39 DE_277 3.36321062 1.09113550 -2.7899650 system 2.7.9 ## 40 DE_288 4.98204788 2.66509747 -1.2160031 system 2.7.9 ## 41 DE_290 2.71675834 1.80294964 -2.0781509 system 2.7.9 %in% permite detectar si un elemento esta en un objeto. Devuelve TRUE/FALSE. Puede usarse como un complemento de los comparadores ==, &gt;, &lt;= en sentencias if(){} if (T) {&quot;ok&quot;} ## [1] &quot;ok&quot; if (F) {&quot;ok&quot;} if (&quot;system 2.7.9&quot; %in% final.data.with.terms.nas$terms.col) {&quot;ok&quot;} ## [1] &quot;ok&quot; # &quot;system 2.7.9&quot; est√° en &quot;final.data...&quot; as√≠ que TRUE -&gt; &#39;ok&#39; final.data.with.terms.nas %&gt;% { if (&quot;system 2.7.9&quot; %in% final.data.with.terms.nas$terms.col) print(&quot;ok&quot;) else str_extract(.[[&quot;terms.col&quot;]], &quot;system.*&quot;) } %&gt;% na.omit() %&gt;% unique() -&gt; unicos ## [1] &quot;ok&quot; mis.datos &lt;- list(final.data.with.terms.nas, unicos, c(1, 2, 4, 5, 5, NA)) 3.5 Ejemplo de vida real library(tidyverse) library(magrittr) #fba &lt;- read.csv(&#39;clase_3_datos.csv&#39;) fba &lt;- read_csv(&#39;https://raw.githubusercontent.com/DeepenData/clases/944d24e71390c75ab16c9a00a941ce6f3de1369d/03-mutate-pipes-regex/clase_3_datos.csv&#39;) ## Warning: Missing column names filled in: &#39;X1&#39; [1] ## ## ‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## cols( ## X1 = col_double(), ## ID = col_character(), ## Name = col_character(), ## Reaction = col_character(), ## Flux = col_double(), ## Sensitivity = col_double() ## ) fba %&lt;&gt;% select(c(&#39;ID&#39;, matches(&#39;flux&#39;), contains(&#39;Reac&#39;),matches(&#39;*ame.*|sen&#39;))) %&gt;% filter(!str_detect(ID, regex(&#39;DM|sink&#39;, ignore_case = T))) %&gt;% mutate(`Node type` = ifelse(str_detect(Reaction, regex(&#39;\\\\[[a-z]A\\\\]&#39;, ignore_case = T)), &#39;Astrocyte&#39;, NA)) %&gt;% mutate(`Node type` = ifelse(str_detect(Reaction, regex(&#39;\\\\[[a-z]N\\\\]&#39;, ignore_case = T)), &#39;Neuron&#39;, `Node type`)) %&gt;% filter(Flux &gt; 0.1 &amp; abs(Sensitivity) &gt; 0) %&gt;% column_to_rownames(&quot;ID&quot;) fba ## Flux ## ENO 7.0380 ## GAPD 7.0380 ## GLCt1r 3.5190 ## GLNS 4.2228 ## HEX1 3.5190 ## PFK 3.5190 ## PYK 7.0380 ## BTNt4i_Int 2.1114 ## GLUt6_Int 4.2228 ## NaKt_Int 2.8152 ## ASPGLUm_Neuron 10.8026 ## CSm_Neuron 10.8026 ## CYOOm2_Neuron 32.4078 ## CYOR-u10m_Neuron 64.8156 ## ENO_Neuron 3.7646 ## FUMm_Neuron 10.8026 ## GAPD_Neuron 3.7646 ## GLUNm_Neuron 4.2228 ## HEX1_Neuron 1.8823 ## HMGCOASim_Neuron 10.8026 ## ICDHyrm_Neuron 10.8026 ## L-LACt2r_Neuron 7.0380 ## LDH_L_Neuron 7.0380 ## MDHm_Neuron 21.6052 ## NH4t3r_Neuron 4.2228 ## PFK_Neuron 1.8823 ## PGI_Neuron 1.8823 ## PIt2m_Neuron 151.2364 ## PYRt2m_Neuron 10.8026 ## SUCD1m_Neuron 10.8026 ## GLNtN1_Neuron 4.2228 ## NaEX_Neuron 346.7718 ## GLCt1r_Neuron 1.8823 ## Reaction ## ENO 2pg[cA] &lt;=&gt; h2o[cA] + pep[cA] ## GAPD g3p[cA] + nad[cA] + pi[cA] &lt;=&gt; 13dpg[cA] + h[cA] + nadh[cA] ## GLCt1r glc-D[e] --&gt; glc-D[cA] ## GLNS atp[cA] + glu-L[cA] + nh4[cA] --&gt; adp[cA] + gln-L[cA] + h[cA] + pi[cA] ## HEX1 atp[cA] + glc-D[cA] --&gt; adp[cA] + g6p[cA] + h[cA] ## PFK atp[cA] + f6p[cA] --&gt; adp[cA] + fdp[cA] + h[cA] ## PYK adp[cA] + h[cA] + pep[cA] --&gt; atp[cA] + pyr[cA] ## BTNt4i_Int btn[I] + h[cA] --&gt; btn[cA] + h[I] ## GLUt6_Int glu-L[I] + h[I] + k[cA] + 3.0 na1[I] --&gt; glu-L[cA] + h[cA] + k[I] + 3.0 na1[cA] ## NaKt_Int atp[cA] + h2o[cA] + 2.0 k[I] + 3.0 na1[cA] --&gt; adp[cA] + h[cA] + 2.0 k[cA] + 3.0 na1[I] + pi[cA] ## ASPGLUm_Neuron asp-L[mN] + glu-L[cN] + h[cN] --&gt; asp-L[cN] + glu-L[mN] + h[mN] ## CSm_Neuron accoa[mN] + h2o[mN] + oaa[mN] --&gt; cit[mN] + coa[mN] + h[mN] ## CYOOm2_Neuron 4.0 focytC[mN] + 8.0 h[mN] + o2[mN] --&gt; 4.0 ficytC[mN] + 2.0 h2o[mN] + 4.0 h[cN] ## CYOR-u10m_Neuron 2.0 ficytC[mN] + 2.0 h[mN] + q10h2[mN] --&gt; 2.0 focytC[mN] + 4.0 h[cN] + q10[mN] ## ENO_Neuron 2pg[cN] &lt;=&gt; h2o[cN] + pep[cN] ## FUMm_Neuron fum[mN] + h2o[mN] &lt;=&gt; mal-L[mN] ## GAPD_Neuron g3p[cN] + nad[cN] + pi[cN] &lt;=&gt; 13dpg[cN] + h[cN] + nadh[cN] ## GLUNm_Neuron gln-L[mN] + h2o[mN] --&gt; glu-L[mN] + nh4[mN] ## HEX1_Neuron atp[cN] + glc-D[cN] --&gt; adp[cN] + g6p[cN] + h[cN] ## HMGCOASim_Neuron aacoa[mN] + accoa[mN] + h2o[mN] --&gt; coa[mN] + h[mN] + hmgcoa[mN] ## ICDHyrm_Neuron icit[mN] + nadp[mN] &lt;=&gt; akg[mN] + co2[mN] + nadph[mN] ## L-LACt2r_Neuron h[I] + lac-L[I] --&gt; h[cN] + lac-L[cN] ## LDH_L_Neuron lac-L[cN] + nad[cN] --&gt; h[cN] + nadh[cN] + pyr[cN] ## MDHm_Neuron mal-L[mN] + nad[mN] &lt;=&gt; h[mN] + nadh[mN] + oaa[mN] ## NH4t3r_Neuron h[I] + nh4[cN] &lt;=&gt; h[cN] + nh4[I] ## PFK_Neuron atp[cN] + f6p[cN] --&gt; adp[cN] + fdp[cN] + h[cN] ## PGI_Neuron g6p[cN] &lt;=&gt; f6p[cN] ## PIt2m_Neuron h[cN] + pi[cN] &lt;=&gt; h[mN] + pi[mN] ## PYRt2m_Neuron h[cN] + pyr[cN] &lt;=&gt; h[mN] + pyr[mN] ## SUCD1m_Neuron fad[mN] + succ[mN] &lt;=&gt; fadh2[mN] + fum[mN] ## GLNtN1_Neuron gln-L[I] + h[cN] + na1[I] &lt;=&gt; gln-L[cN] + h[I] + na1[cN] ## NaEX_Neuron na1[e] &lt;=&gt; na1[cN] ## GLCt1r_Neuron glc-D[e] --&gt; glc-D[cN] ## Name ## ENO enolase Astrocyte ## GAPD glyceraldehyde-3-phosphate dehydrogenase Astrocyte ## GLCt1r glucose transport (uniport) Astrocyte ## GLNS glutamine synthetase Astrocyte ## HEX1 hexokinase (D-glucose:ATP) Astrocyte ## PFK phosphofructokinase Astrocyte ## PYK pyruvate kinase Astrocyte ## BTNt4i_Int Biotin uptake (antiport) Interstitial And Synapse ## GLUt6_Int Glutamate transport via Na, H symport and K antiport Interstitial And Synapse ## NaKt_Int Na+/K+ exchanging ATPase Interstitial And Synapse ## ASPGLUm_Neuron aspartate-glutamate mitochondrial shuttle Neuron ## CSm_Neuron citrate synthase Neuron ## CYOOm2_Neuron cytochrome c oxidase, mitochondrial Complex IV Neuron ## CYOR-u10m_Neuron ubiquinol-6 cytochrome c reductase, Complex III Neuron ## ENO_Neuron enolase Neuron ## FUMm_Neuron fumarase, mitochondrial Neuron ## GAPD_Neuron glyceraldehyde-3-phosphate dehydrogenase Neuron ## GLUNm_Neuron glutaminase (mitochondrial) Neuron ## HEX1_Neuron hexokinase (D-glucose:ATP) Neuron ## HMGCOASim_Neuron Hydroxymethylglutaryl CoA synthase (ir) Neuron ## ICDHyrm_Neuron Isocitrate dehydrogenase (NADP+) Neuron ## L-LACt2r_Neuron L-lactate reversible transport via proton symport Neuron ## LDH_L_Neuron L-lactate dehydrogenase Neuron ## MDHm_Neuron malate dehydrogenase, mitochondrial Neuron ## NH4t3r_Neuron ammonia transport via proton antiport Neuron ## PFK_Neuron phosphofructokinase Neuron ## PGI_Neuron glucose-6-phosphate isomerase Neuron ## PIt2m_Neuron phosphate transporter, mitochondrial Neuron ## PYRt2m_Neuron pyruvate mitochondrial transport via proton symport Neuron ## SUCD1m_Neuron succinate dehydrogenase Neuron ## GLNtN1_Neuron Glutamine transporter Neuron ## NaEX_Neuron Sodium transport (added for simulation) ## GLCt1r_Neuron Glucose transporter_Neuron ## Sensitivity Node type ## ENO 9.020562e-16 Astrocyte ## GAPD 1.110223e-15 Astrocyte ## GLCt1r 6.652000e+01 Astrocyte ## GLNS 1.332268e-15 Astrocyte ## HEX1 -1.998401e-15 Astrocyte ## PFK -1.998401e-15 Astrocyte ## PYK 2.153833e-14 Astrocyte ## BTNt4i_Int 3.328007e-31 Astrocyte ## GLUt6_Int -3.328007e-31 Astrocyte ## NaKt_Int 2.220446e-16 Astrocyte ## ASPGLUm_Neuron 2.109424e-15 Neuron ## CSm_Neuron -1.165734e-15 Neuron ## CYOOm2_Neuron -4.884981e-15 Neuron ## CYOR-u10m_Neuron -1.776357e-15 Neuron ## ENO_Neuron 8.881784e-16 Neuron ## FUMm_Neuron -8.881784e-16 Neuron ## GAPD_Neuron -1.054712e-15 Neuron ## GLUNm_Neuron 8.881784e-16 Neuron ## HEX1_Neuron 1.776357e-15 Neuron ## HMGCOASim_Neuron 2.386980e-15 Neuron ## ICDHyrm_Neuron 8.881784e-16 Neuron ## L-LACt2r_Neuron 3.328007e-31 Neuron ## LDH_L_Neuron -6.106227e-16 Neuron ## MDHm_Neuron -2.775558e-16 Neuron ## NH4t3r_Neuron 1.776357e-15 Neuron ## PFK_Neuron 1.776357e-15 Neuron ## PGI_Neuron -2.842171e-14 Neuron ## PIt2m_Neuron -5.551115e-17 Neuron ## PYRt2m_Neuron 3.330669e-16 Neuron ## SUCD1m_Neuron -6.661338e-16 Neuron ## GLNtN1_Neuron -2.664535e-15 Neuron ## NaEX_Neuron 2.812565e-15 Neuron ## GLCt1r_Neuron 6.000000e+01 Neuron "],["clase-4-descargas-desde-repositorios-e-interacci√≥n-con-objetos-descargados.html", "4 CLASE 4 - Descargas desde repositorios e interacci√≥n con objetos descargados", " 4 CLASE 4 - Descargas desde repositorios e interacci√≥n con objetos descargados library(readr) library(tidyverse) genes_url &lt;- &#39;https://raw.githubusercontent.com/DeepenData/clases/fb3e5b3f7c9aca0c13d7eebe217cde9fe6b087bf/04-filters-programacion-funcional-apply-map/recon3_genes_to_reactionIDs.csv&#39; metabolites_url &lt;- &#39;https://raw.githubusercontent.com/DeepenData/clases/fb3e5b3f7c9aca0c13d7eebe217cde9fe6b087bf/04-filters-programacion-funcional-apply-map/recon3_metabolite_metadata.csv&#39; reactions_url &lt;- &#39;https://raw.githubusercontent.com/DeepenData/clases/fb3e5b3f7c9aca0c13d7eebe217cde9fe6b087bf/04-filters-programacion-funcional-apply-map/recon3_reactions_metadata.csv&#39; import_my_csv &lt;- function(url){readr::read_csv(url) %&gt;% dplyr::select(-matches(&quot;x1&quot;)) %&gt;% return} genes_url %&gt;% import_my_csv -&gt; genes metabolites_url %&gt;% import_my_csv -&gt; metabolites reactions_url %&gt;% import_my_csv -&gt; reactions library(magrittr) list(genes_url,reactions_url, metabolites_url) -&gt; my_list lapply(my_list, import_my_csv) -&gt; recon3_list.lapply sapply(my_list, import_my_csv) -&gt; recon3_list.sapply purrr::map(my_list, import_my_csv) -&gt; recon3_list.map list(recon3_list.lapply,recon3_list.sapply,recon3_list.map) %&gt;% map(length) ## [[1]] ## [1] 3 ## ## [[2]] ## [1] 3 ## ## [[3]] ## [1] 3 my_names &lt;- c(&#39;genes&#39;, &#39;reactions&#39;, &#39;metabolites&#39;) recon3_list.map %&lt;&gt;% purrr::set_names(my_names) rename_ids &lt;- function(df){df %&gt;% as_tibble %&gt;% rename_with(tolower) %&gt;% rename_with(~str_replace(., &#39;.*id.*&#39;,&#39;ID&#39;))} rename_ids &lt;- function(df){df %&gt;% as_tibble %&gt;% rename_with(~str_replace(.,regex(&#39;.*iD.*&#39;, ignore_case = T) ,&#39;ID&#39;))} recon3_list.map$genes %&gt;% rename_ids ## # A tibble: 2,248 x 2 ## ID Reactions ## &lt;dbl&gt; &lt;chr&gt; ## 1 26.1 [&#39;RE0690E&#39;, &#39;13DAMPPOX&#39;, &#39;42A12BOOX&#39;, &#39;r0281&#39;, &#39;RE0827E&#39;, &#39;TRYPTAOX&#39;‚Ä¶ ## 2 314. [&#39;13DAMPPOX&#39;, &#39;42A12BOOX&#39;, &#39;TRYPTAOX&#39;, &#39;PEAMNO&#39;, &#39;HISTASE&#39;, &#39;MAOX&#39;, ‚Ä¶ ## 3 8639. [&#39;MAOX&#39;, &#39;AACTOOR&#39;, &#39;13DAMPPOX&#39;, &#39;42A12BOOX&#39;, &#39;PTRCOX1&#39;, &#39;MHISOR&#39;] ## 4 314. [&#39;13DAMPPOX&#39;, &#39;42A12BOOX&#39;, &#39;TRYPTAOX&#39;, &#39;PEAMNO&#39;, &#39;HISTASE&#39;, &#39;MAOX&#39;, ‚Ä¶ ## 5 1591. [&#39;24_25VITD2Hm&#39;, &#39;24_25VITD3Hm&#39;] ## 6 1594. [&#39;25VITD2Hm&#39;, &#39;25HVITD3c&#39;, &#39;25VITD3Hm&#39;] ## 7 10993. [&#39;r0060&#39;, &#39;2AMACHYD&#39;, &#39;THRD_L&#39;, &#39;SERHL&#39;] ## 8 6818. [&#39;5ADTSTSTERONESULT&#39;, &#39;2AMACSULT&#39;, &#39;NRPPHRSULT&#39;, &#39;HMR_6844&#39;, &#39;CHSTER‚Ä¶ ## 9 89874. [&#39;2OXOADPTm&#39;, &#39;r0879&#39;, &#39;2AMADPTm&#39;] ## 10 3948. [&#39;2HIVc&#39;, &#39;GLXO1&#39;, &#39;2HBO&#39;, &#39;HPYRR2x&#39;, &#39;r0173&#39;, &#39;LDH_L&#39;, &#39;2H3MVc&#39;, &#39;M‚Ä¶ ## # ‚Ä¶ with 2,238 more rows map(recon3_list.map,rename_ids ) -&gt;recon3_list #data.table::setnames(my_names) Filter recon3_list %&gt;%pluck(&#39;genes&#39;) %&gt;% filter(ID == 314.2) ## # A tibble: 1 x 2 ## ID Reactions ## &lt;dbl&gt; &lt;chr&gt; ## 1 314. [&#39;13DAMPPOX&#39;, &#39;42A12BOOX&#39;, &#39;TRYPTAOX&#39;, &#39;PEAMNO&#39;, &#39;HISTASE&#39;, &#39;MAOX&#39;, &#39;PT‚Ä¶ recon3_list %&gt;%pluck(&#39;genes&#39;) %&gt;% filter(ID %in% c(3948.1,314.2)) ## # A tibble: 2 x 2 ## ID Reactions ## &lt;dbl&gt; &lt;chr&gt; ## 1 314. [&#39;13DAMPPOX&#39;, &#39;42A12BOOX&#39;, &#39;TRYPTAOX&#39;, &#39;PEAMNO&#39;, &#39;HISTASE&#39;, &#39;MAOX&#39;, &#39;PT‚Ä¶ ## 2 3948. [&#39;2HIVc&#39;, &#39;GLXO1&#39;, &#39;2HBO&#39;, &#39;HPYRR2x&#39;, &#39;r0173&#39;, &#39;LDH_L&#39;, &#39;2H3MVc&#39;, &#39;MCLO‚Ä¶ recon3_list %&gt;%pluck(&#39;genes&#39;) %&gt;% filter(str_detect(ID,&quot;^284.*0.*&quot;)) %&gt;% .[[&quot;Reactions&quot;]] %&gt;% .[2] -&gt; my_reactions my_reactions %&lt;&gt;% str_split(&#39;,&#39;, simplify = T) %&gt;% str_extract(&#39;\\\\w+&#39;) recon3_list %&gt;%pluck(&#39;reactions&#39;) %&gt;% filter(ID %in% my_reactions) ## # A tibble: 5 x 5 ## ID rxn_names reactions rxn_bounds rxn_subsystems ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 HMR_08‚Ä¶ Beta-N-Acetylhe‚Ä¶ gbside_hs_c + h2o_c --‚Ä¶ (0.0, 100‚Ä¶ Glycosphingolipid‚Ä¶ ## 2 HMR_08‚Ä¶ Beta-N-Acetylhe‚Ä¶ gbside_hs_l + h2o_l --‚Ä¶ (0.0, 100‚Ä¶ Glycosphingolipid‚Ä¶ ## 3 HMR_08‚Ä¶ Beta-N-Acetylhe‚Ä¶ ga2_hs_c + h2o_c --&gt; a‚Ä¶ (0.0, 100‚Ä¶ Glycosphingolipid‚Ä¶ ## 4 HMR_08‚Ä¶ Beta-N-Acetylhe‚Ä¶ gm2_hs_c + h2o_c --&gt; a‚Ä¶ (0.0, 100‚Ä¶ Glycosphingolipid‚Ä¶ ## 5 HMR_08‚Ä¶ Beta-N-Acetylhe‚Ä¶ M02013_l + h2o_l --&gt; M‚Ä¶ (0.0, 100‚Ä¶ Glycosphingolipid‚Ä¶ Creando funciones name_pattern_to_IDs &lt;- function(my_list, entry, name_pattern){ regex(name_pattern, ignore_case = T) -&gt; name_pattern my_list %&gt;% pluck(entry) %&gt;% names %&gt;% str_extract(regex(&#39;.*nAme.*&#39;, ignore_case = T)) %&gt;% na.exclude %&gt;% as.character -&gt; my_col my_list %&gt;% pluck(entry) %&gt;% select(c(&quot;ID&quot;, my_col)) %&gt;%filter(str_detect(.[[2]],name_pattern)) %&gt;% .[[&#39;ID&#39;]] %&gt;% return() } name_pattern_to_IDs(recon3_list, &#39;reactions&#39;, &#39;glutamate&#39;) -&gt; found_rxns ## Note: Using an external vector in selections is ambiguous. ## ‚Ñπ Use `all_of(my_col)` instead of `my_col` to silence this message. ## ‚Ñπ See &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;. ## This message is displayed once per session. reactionIDs_to_genes &lt;- function(reaction_list){ recon3_list %&gt;%pluck(&#39;genes&#39;) -&gt; genes_df genes_df$Reactions %&gt;% str_extract_all(&#39;\\\\w+&#39;) %&gt;% tibble( gene = genes_df$ID, rxn=.) %&gt;% unnest(cols = rxn) -&gt; gene_rxns gene_rxns %&gt;% filter(rxn %in% reaction_list) %&gt;% .[[&quot;gene&quot;]] %&gt;% unique() %&gt;% return() } reactionIDs_to_genes(found_rxns) -&gt; found_genes name_pattern_to_IDs_2 &lt;- function(pattern){name_pattern_to_IDs(recon3_list, &#39;reactions&#39;, pattern)} purrr::compose(reactionIDs_to_genes, name_pattern_to_IDs_2 ) -&gt; rxn_name_to_genes rxn_name_to_genes(&#39;atp&#39;) ## [1] 4363.1 6571.1 6570.1 6572.1 47.2 47.1 ## [7] 204.1 205.1 26289.1 245972.1 525.1 535.1 ## [13] 10312.1 523.1 10312.2 50617.1 51606.1 534.1 ## [19] 529.1 245973.1 9114.1 9550.1 127124.1 50617.2 ## [25] 526.1 528.1 51382.1 51606.2 533.1 127124.2 ## [31] 90423.1 9296.1 50617.3 527.1 8992.1 23545.1 ## [37] 51606.3 534.2 528.2 954.1 953.1 956.1 ## [43] 957.1 955.1 954.2 377841.1 292.1 291.1 ## [49] 293.1 140679.1 10599.1 8714.1 1244.1 28234.1 ## [55] 491.1 490.1 492.1 493.1 6579.1 8647.1 ## [61] 19.1 1160.1 548596.1 1159.1 1152.1 1158.1 ## [67] 83549.1 7371.1 51727.1 1633.1 1716.1 11309.1 ## [73] 60386.1 7083.1 7084.1 11001.1 10257.1 10999.1 ## [79] 376497.1 57030.1 246213.1 57084.1 3098.4 2645.2 ## [85] 3098.1 2645.3 3098.5 3098.3 2645.1 3101.1 ## [91] 3098.2 80201.1 3099.1 495.1 496.1 4598.1 ## [97] 23439.1 476.1 481.1 480.1 478.1 477.1 ## [103] 482.1 483.1 4832.1 4830.2 29922.1 10201.1 ## [109] 29922.2 4831.1 4830.1 4833.1 26873.1 117283.1 ## [115] 9807.1 51447.1 113278.1 54963.1 80347.1 5313.1 ## [121] 5211.1 132158.1 55229.1 79646.1 80025.1 53354.1 ## [127] 64241.1 64240.1 10057.1 215.1 5825.1 85320.1 ## [133] 10057.2 122481.1 203.1 2987.1 100507855.1 3705.1 ## [139] 23262.1 9677.1 26007.1 9551.1 10632.1 516.1 ## [145] 514.2 27109.1 515.2 509.1 518.2 514.1 ## [151] 515.3 517.1 515.1 513.1 522.3 509.2 ## [157] 517.2 498.3 522.2 518.3 498.1 521.1 ## [163] 4905.1 9551.2 513.2 539.1 267020.1 516.2 ## [169] 10476.2 506.1 522.5 9551.3 518.1 522.4 ## [175] 10476.1 498.2 522.1 c(&quot;glucose&quot;,&quot;phenyl&quot;,&quot;rna&quot;) -&gt; some_keywords map(some_keywords, rxn_name_to_genes) %&gt;% set_names(some_keywords) %&gt;% tibble(genes=., keyword = some_keywords) %&gt;% unnest(cols = c(genes)) ## # A tibble: 112 x 2 ## genes keyword ## &lt;dbl&gt; &lt;chr&gt; ## 1 57818. glucose ## 2 92579. glucose ## 3 2538. glucose ## 4 6517. glucose ## 5 6515. glucose ## 6 6513. glucose ## 7 84920. glucose ## 8 5169. glucose ## 9 5167. glucose ## 10 66035. glucose ## # ‚Ä¶ with 102 more rows set_long_df &lt;- function(a_list, keywords){a_list %&gt;% set_names(keywords) %&gt;% tibble(genes=., keyword = keywords) %&gt;% unnest(cols = c(genes))} some_keywords %&gt;%map(rxn_name_to_genes)%&gt;% set_long_df(some_keywords) ## # A tibble: 112 x 2 ## genes keyword ## &lt;dbl&gt; &lt;chr&gt; ## 1 57818. glucose ## 2 92579. glucose ## 3 2538. glucose ## 4 6517. glucose ## 5 6515. glucose ## 6 6513. glucose ## 7 84920. glucose ## 8 5169. glucose ## 9 5167. glucose ## 10 66035. glucose ## # ‚Ä¶ with 102 more rows keywords_to_genes &lt;- function(some_keywords){some_keywords %&gt;%map(rxn_name_to_genes)%&gt;% set_long_df(some_keywords)} keywords_to_genes(c(&quot;reductase&quot;,&quot;peroxide&quot;,&quot;thioredoxin&quot;,&quot;glutathione&quot;) ) %&gt;% tidyr::nest(genes= genes) -&gt; resultados #%&gt;% unnest(genes) resultados%&gt;% unnest(genes) %&gt;% count(keyword) %&gt;% mutate(&quot;%&quot; = 100*n/sum(n)) ## # A tibble: 4 x 3 ## keyword n `%` ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 glutathione 30 12.0 ## 2 peroxide 14 5.58 ## 3 reductase 200 79.7 ## 4 thioredoxin 7 2.79 "]]
