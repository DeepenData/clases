---
title: 'Primera clase - Taller DeepenData: R intermedio-avanzado'
author: "Acevedo A., Alejandro & Muñoz, Manuel. Universidad de Chile. Corresponding: manuel.munoz.g@ug.uchile.cl"
date: "24-09-2020"
output:
  html_document:
    df_print: paged
Corresponding: manuel.munoz.g@ug.uchile.cl
---

# Importación y escritura. 

<iframe width="560" height="315" src="https://youtu.be/Oz7hvrESRt4?t=235" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

[RPub de esta clase](https://rpubs.com/DeepenData/665531)

```{r Comentario sobre rutas, echo=TRUE, message=FALSE, warning=FALSE, eval=FALSE}
getwd()
paste0(getwd(),'/hola')
file.path(getwd(),'hola')
file.path(getwd(),'hola','hola')
```

## Manipulando data local


```
mtcars:

    mpg: Miles/(US) gallon
    cyl: Number of cylinders
    disp: Displacement (cu.in.)
    hp: Gross horsepower
    drat: Rear axle ratio
    wt: Weight (1000 lbs)
    qsec: 1/4 mile time
    vs: V/S
    am: Transmission (0 = automatic, 1 = manual)
    gear: Number of forward gears
    carb: Number of carburetors
```

```{r Chunk que carga packs de datos, echo=TRUE, message=FALSE, warning=FALSE}
#install.packages("devtools", dependencies = TRUE)
#install.packages("curl", dependencies = TRUE)
#install.packages("tidyverse", dependencies = TRUE)
library(readr)
my.data <- mtcars
my.data
# Exportando data
write_csv(my.data,  path = 'mtcars.csv' ) # Coma Separated Value
write_tsv(my.data,  path = 'mtcars.tsv')  # Tab Separated Value
write_delim(my.data,path = 'mtcars.txt', delim = ";") # Texto con delimitador ";"
write_delim(my.data,path = 'mtcars.hola', delim = "*_*") # Texto con delimitador "*_*"

openxlsx::write.xlsx(my.data, file = "mtcars.xlsx") # Excel
```

```{r Importando Data local, echo=TRUE, message=FALSE, warning=FALSE}
# (Re)Importando data
mtcars.csv<-read_csv('mtcars.csv')
mtcars.tsv<-read_tsv('mtcars.tsv')
mtcars.txt<-read_delim('mtcars.txt', delim = ";")
mtcars.hola<-read_delim('mtcars.hola', delim = "*")

library(readxl) # Importando un Excel
mtcars.xlsx<-read_excel('mtcars.xlsx')
```

## Manipulando columna rownames

```{r, echo=TRUE, message=FALSE, warning=FALSE}
library(tibble) 
rownames_to_column(my.data, var = "Car brand")   -> my.data.2
library(magrittr) # 
my.data %>% rownames_to_column(var = "Car brand")-> my.data.2
#####Con pipes#############
my.data.2 %>%   write_csv('mtcars.csv')
my.data.2 %>%   write_tsv('mtcars.tsv')
my.data.2 %>% write_delim('mtcars.txt',  delim = ";")
my.data.2 %>% write_delim('mtcars.hola', delim = "*_*")
my.data.2 %>% openxlsx::write.xlsx("mtcars.xlsx")

###########Lectura##################
read_csv('mtcars.csv', skip = 0)                         ->mtcars.csv
read_tsv('mtcars.tsv', skip = 0)                         ->mtcars.tsv
read_delim('mtcars.txt', delim = ";", skip = 0)          ->mtcars.txt
read_delim('mtcars.hola', delim = "*_*", skip = 0)       ->mtcars.hola
read_excel('mtcars.xlsx', skip = 0)                      ->mtcars.xlsx

########Chequear igualdad###############
library(dplyr)
all_equal(mtcars.csv,mtcars.tsv)   # La data del csv deberia ser igual a la del tsv
all_equal(mtcars.txt,mtcars.hola)  # La data del txt deberia ser igual a la del .hola
all_equal(mtcars.hola,mtcars.xlsx) # La data del txt deberia ser igual a la del Excel

list(mtcars.csv, mtcars.tsv, mtcars.txt, mtcars.hola,mtcars.xlsx) %>% unique() %>% length() # TODO: porque da dos salidas? Una es una tabla y el otro es una consola?

```

## Descargando data online

```{r Descargando data en linea, echo=TRUE, message=FALSE, warning=FALSE}
library(utils)
library(httr)
#Para LINUX y WINDOMS  usar:
my.github.url <- 'https://github.com/DeepenData/Computational-Biology-and-Bioinformatics/raw/master/Wang2018_supplemental_DEGs.xlsx'
GET(my.github.url, write_disk(tf <- tempfile(fileext = ".xlsx"))) 
hola.github <- read_excel(tf, skip = 1) 
hola.github 
```


```{r Descargando data en linea, echo=TRUE, message=FALSE, warning=FALSE}
###Dropbox
my.dropbox.url <- 'https://www.dropbox.com/s/j3kiivpcbghpb4v/log2FC.csv'
#Para windows usar:
download.file(url= my.dropbox.url,  destfile= 'log2FC.csv', method = "libcurl") 
#Para linux usar:
download.file(url= my.dropbox.url,  destfile= 'log2FC.csv', method = "wget") 
hola.dropbox <- read_csv("log2FC.csv")
hola.dropbox
```
```{r Descargando data en linea, echo=TRUE, message=FALSE, warning=FALSE}
library(utils)
library(httr)
###Sitio web arbitrario
#Para LINUX USAR:
my.supplementary.url <- 'https://www.pnas.org/highwire/filestream/794560/field_highwire_adjunct_files/0/pnas.1800165115.sd01.xlsx'
download.file(url= my.supplementary.url,  destfile= 'pnas.1800165115.sd01.xlsx', method = "wget") # ERROR!
hola.supplementary <- read_excel("pnas.1800165115.sd01.xlsx")
#Para LINUX y WINDOMS  usar:
GET(my.supplementary.url, write_disk(tf <- tempfile(fileext = ".xlsx")))
hola.supplementary <- read_excel(tf, skip = 1) 
hola.supplementary 
```

```{r Leyendo directamente data en linea, paged.print=TRUE,  message=FALSE, warning=FALSE}
read_csv('https://raw.githubusercontent.com/DeepenData/Computational-Biology-and-Bioinformatics/master/labels.csv')
```

## Genomica

biomartr tutorials:

- https://docs.ropensci.org/biomartr/articles/
- https://cran.r-project.org/web/packages/biomartr/vignettes/Sequence_Retrieval.html
- https://cran.r-project.org/web/packages/biomartr/readme/README.html

```{r Instalación de pre-requisitos Bioconductor, eval=FALSE}
install.packages("BiocManager", dependencies = TRUE)
BiocManager::install()
BiocManager::install("Biostrings")
BiocManager::install("biomaRt")
install.packages("biomartr")#, dependencies = TRUE)
```

```{r Datos Omicos, warning=FALSE, paged.print=TRUE,  message=FALSE, warning=FALSE}
library(biomartr)
library(magrittr)
#Objetos clase DNAStringSet
inmortal <- getGenome( db       = "refseq", #Más bases de datos
                       organism = "Thermococcus gammatolerans",
                       path     = file.path("_ncbi_downloads","genomes") ) %>%  read_genome()
inmortal
```
<!-- WLS2 es malo por EEE (Embrace, Extend and Extinguish o EEE) -->

Dato impresionante: se pueden leer genomas directamente desde el url del NCBI

```{r Datos Omicos Humanos, message=FALSE, warning=FALSE, paged.print=TRUE}

url.NCBI <- 'ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.35_GRCh38.p9/GCF_000001405.35_GRCh38.p9_cds_from_genomic.fna.gz'
human    <- read_genome(url.NCBI)
human %>% names() %>% sample(10)
human 
```

## Epigenomica

Para más información sobre GEOquery y consultas de bases de datos de expresión génica ver la siguiente clase y rpub:

<iframe width="560" height="315" src="https://www.youtube.com/watch?v=gtJni7z9xTg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> 

https://rpubs.com/DeepenData/622645 

```{r Instala GEOquery, message=FALSE, warning=FALSE}
#if (!requireNamespace("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")
#BiocManager::install("GEOquery")
library(GEOquery)
```

```{r Descargando datasets GEO, paged.print=TRUE}
gset = getGEO("GSE36278") # Descarga un dataset de
fData(gset[[1]])          # Lista las sondas del set
```

## Transcriptomica

```{r Descarga datasets de transcriptomica, message=FALSE, warning=FALSE, paged.print=TRUE}
inmortal <- getRNA( db       = "refseq", #Más bases de datos
                       organism = "Thermococcus gammatolerans",
                       path     = file.path("_ncbi_downloads","transcriptome") ) %>%  read_rna()

inmortal
inmortal %>% names() %>% sample(10)
```

## Proteomica

```{r Descarga datasets de proteomica, message=FALSE, warning=FALSE}
download_species <- c("Thermococcus gammatolerans", 
                      "Thermotoga maritima")
# retrieve these three species from NCBI RefSeq                       
mis.proteomas <- getProteomeSet("refseq", organisms = download_species, path = "set_proteomes")

read_proteome(mis.proteomas[1])
read_proteome(mis.proteomas[2])
```

Proteómica Importing de [ProteomExchange](http://www.proteomexchange.org/) [R for Proteomics]( https://bioconductor.org/packages/release/data/experiment/vignettes/RforProteomics/inst/doc/RforProteomics.html)

## Estudios diferenciales

```{r Instalando RforProteomics, warning=FALSE, eval=FALSE}
BiocManager::install()
BiocManager::install("RforProteomics",
                     ask = F, 
                     dependencies = TRUE,
                     type = "source",
                     checkBuilt = TRUE)
```

```{r Corriendo RforProteomics}
## Experiment information
library("rpx")
px1 <- PXDataset("PXD000001")
pxfiles(px1)^
```
Para instalar MSnbase:

Dentro de la terminal:

```{bash, echo=TRUE, eval=FALSE}
sudo apt-cache search libnetcdf 
sudo apt-get update 
sudo apt-get install libnetcdf-c++4-1
```
Usar la siguiente página omitiendo los pasos de instalación de R 4.0

[Cartografos](https://rtask.thinkr.fr/installation-of-r-4-0-on-ubuntu-20-04-lts-and-tips-for-spatial-packages/)

```{r}
#BiocManager::install("MSnbase", ask = T, dependencies = TRUE,   type = "source", checkBuilt = TRUE)
library(magrittr)
library(Biobase)
library(MSnbase)

## Downloading the mzTab data
mztab <- pxget(px1, "PXD000001_mztab.txt")
qnt <- readMzTabData(mztab, what = "PEP", version = "0.9")
```

TMT: https://en.wikipedia.org/wiki/Tandem_mass_tag

```{r message=FALSE, warning=FALSE}
sampleNames(qnt) <- reporterNames(TMT6)
#head(exprs(qnt))
qnt <- filterNA(qnt)
processingData(qnt)
## combine into proteins
## - using the 'accession' feature meta data
## - sum the peptide intensities
protqnt <- combineFeatures(qnt,
                           groupBy = fData(qnt)$accession,
                           fun = sum)


protqnt %>% exprs %>% tail()
```
```{r fig.height=3, fig.width=5, message=FALSE, warning=FALSE}
library("RColorBrewer") ## Color palettes
library("ggplot2")  ## Convenient and nice plotting
library("reshape2") ## Flexibly reshape data

cls <- brewer.pal(5, "Set1")
matplot(t(tail(exprs(protqnt), n = 5)), type = "b",
        lty = 1, col = cls,
        ylab = "Protein intensity (summed peptides)",
        xlab = "TMT reporters")
legend("topright", tail(featureNames(protqnt), n=5),
       lty = 1, bty = "n", cex = .8, col = cls)
```

*Multi-omic*

Collection Retrieval

The automated retrieval of collections (= Genome, Proteome, CDS, RNA, GFF, Repeat Masker, AssemblyStats) will make sure that the genome file of an organism will match the CDS, proteome, RNA, GFF, etc file and was generated using the same genome assembly version. One aspect of why genomics studies fail in computational and biological reproducibility is that it is not clear whether CDS, proteome, RNA, GFF, etc files used in a proposed analysis were generated using the same genome assembly file denoting the same genome assembly version. To avoid this seemingly trivial mistake we encourage users to retrieve genome file collections using the biomartr function getCollection() and attach the corresponding output as Supplementary Data to the respective genomics study to ensure computational and biological reproducibility.

By specifying the scientific name of an organism of interest a collection consisting of the genome file, proteome file, CDS file, RNA file, GFF file, Repeat Masker file, AssemblyStats file of the organism of interest can be downloaded and stored locally.

```{r message=FALSE, warning=FALSE}
inmortal_collect <- getCollection( db = "genbank", 
               organism = "Thermococcus gammatolerans", 
               path = file.path("refseq","Collections"))
```
